# å…¨å±€è‡ªåŠ¨åŒ–å¼€å‘èƒ½åŠ›æ¸…å•

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¶é—´**: 2025-10-16
**é€‚ç”¨ç¯å¢ƒ**: macOS with Claude Code + MCP Servers

---

## ğŸ“‹ ç›®å½•

1. [èµ„æºæ¦‚è§ˆ](#èµ„æºæ¦‚è§ˆ)
2. [MCPæœåŠ¡å™¨è¯¦è§£](#mcpæœåŠ¡å™¨è¯¦è§£)
3. [è‡ªåŠ¨åŒ–å¼€å‘åœºæ™¯](#è‡ªåŠ¨åŒ–å¼€å‘åœºæ™¯)
4. [å®æˆ˜ç¤ºä¾‹](#å®æˆ˜ç¤ºä¾‹)
5. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## èµ„æºæ¦‚è§ˆ

### ğŸ¯ æ€»è§ˆç»Ÿè®¡

**å·²é…ç½®èµ„æºæ€»æ•°**: 21ä¸ªMCPæœåŠ¡å™¨ + 5ä¸ªDockeræ•°æ®åº“

**èƒ½åŠ›åˆ†ç±»**:
- ğŸ§  AIèƒ½åŠ›: 2ä¸ªï¼ˆæ€ç»´é“¾ã€è®°å¿†ï¼‰
- ğŸŒ Webèƒ½åŠ›: 4ä¸ªï¼ˆæµè§ˆå™¨ã€æŠ“å–ã€Chromeå·¥å…·ï¼‰
- ğŸ’¾ æ•°æ®åº“: 7ä¸ªï¼ˆNeo4jã€PostgreSQLã€MongoDBã€Redisã€SQLiteã€Prismaï¼‰
- ğŸ¨ å‰ç«¯: 2ä¸ªï¼ˆMagic UIã€æ–‡ä»¶ç³»ç»Ÿï¼‰
- ğŸ”§ å¼€å‘: 4ä¸ªï¼ˆGitHubã€GitLabã€n8nã€Prismaï¼‰
- ğŸ“Š åä½œ: 3ä¸ªï¼ˆNotionã€Slackã€Feishuï¼‰
- ğŸ” ç›‘æ§: 2ä¸ªï¼ˆSentryã€Computer Useï¼‰
- ğŸ“¦ å­˜å‚¨: 1ä¸ªï¼ˆMinIOï¼‰

### ğŸš€ æ ¸å¿ƒä¼˜åŠ¿

1. **ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–** - ä»æ•°æ®é‡‡é›†åˆ°å†…å®¹å‘å¸ƒ
2. **å¤šæ•°æ®åº“æ”¯æŒ** - å…³ç³»å‹ã€æ–‡æ¡£ã€å›¾ã€ç¼“å­˜ã€å¯¹è±¡å­˜å‚¨
3. **AIå¢å¼ºå¼€å‘** - æ€ç»´é“¾æ¨ç†ã€çŸ¥è¯†å›¾è°±è®°å¿†
4. **å®Œæ•´å·¥å…·é“¾** - æµè§ˆå™¨è‡ªåŠ¨åŒ–ã€APIé›†æˆã€æ–‡ä»¶æ“ä½œ
5. **å›¢é˜Ÿåä½œ** - é€šçŸ¥ã€æ–‡æ¡£ã€é¡¹ç›®ç®¡ç†é›†æˆ

---

## MCPæœåŠ¡å™¨è¯¦è§£

### ğŸ§  AIä¸é—®é¢˜è§£å†³

#### 1. Sequential Thinking (æ€ç»´é“¾æ¨ç†)

**èƒ½åŠ›**:
- ç»“æ„åŒ–é—®é¢˜åˆ†è§£
- åŠ¨æ€æ¨ç†å’Œè¿­ä»£
- å‡è®¾éªŒè¯
- åˆ†æ”¯æ€è€ƒ

**é€‚ç”¨åœºæ™¯**:
```python
# åœºæ™¯1: å¤æ‚æ¶æ„è®¾è®¡
é—®é¢˜: "å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜å¹¶å‘çš„å†…å®¹ç”Ÿæˆç³»ç»Ÿï¼Ÿ"
æ€ç»´é“¾æ¨ç†:
1. åˆ†æå¹¶å‘éœ€æ±‚ï¼ˆQPSã€ç”¨æˆ·é‡ï¼‰
2. è¯„ä¼°æŠ€æœ¯æ–¹æ¡ˆï¼ˆæ¶ˆæ¯é˜Ÿåˆ—ã€å¾®æœåŠ¡ï¼‰
3. è€ƒè™‘ç“¶é¢ˆç‚¹ï¼ˆæ•°æ®åº“ã€LLM APIï¼‰
4. è®¾è®¡æ‰©å±•æ–¹æ¡ˆï¼ˆæ°´å¹³æ‰©å±•ã€ç¼“å­˜ç­–ç•¥ï¼‰
5. éªŒè¯å¯è¡Œæ€§
6. ç”Ÿæˆæœ€ç»ˆæ–¹æ¡ˆ

# åœºæ™¯2: Bugè¯Šæ–­
é—®é¢˜: "ç³»ç»Ÿæ€§èƒ½çªç„¶ä¸‹é™50%"
æ€ç»´é“¾æ¨ç†:
1. æ”¶é›†ç—‡çŠ¶ï¼ˆå“åº”æ—¶é—´ã€é”™è¯¯æ—¥å¿—ï¼‰
2. å‡è®¾å¯èƒ½åŸå› ï¼ˆæ•°æ®åº“æ…¢æŸ¥è¯¢ã€å†…å­˜æ³„æ¼ã€ç½‘ç»œé—®é¢˜ï¼‰
3. é€ä¸€éªŒè¯å‡è®¾
4. å®šä½æ ¹æœ¬åŸå› 
5. æå‡ºè§£å†³æ–¹æ¡ˆ
```

**è‡ªåŠ¨åŒ–å¼€å‘ç”¨æ³•**:
```bash
# ä½¿ç”¨Sequential Thinkingåˆ†æå¤æ‚é—®é¢˜
# Claudeä¼šè‡ªåŠ¨ä½¿ç”¨mcp__sequential-thinking__sequentialthinkingå·¥å…·

ç”¨æˆ·: "è®¾è®¡ä¸€ä¸ªå¯æ‰©å±•çš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç³»ç»Ÿ"
Claude:
  - ä½¿ç”¨æ€ç»´é“¾åˆ†è§£é—®é¢˜
  - è¯„ä¼°å¤šç§æ–¹æ¡ˆ
  - ç”Ÿæˆè¯¦ç»†è®¾è®¡
  - éªŒè¯å¯è¡Œæ€§
```

#### 2. Memory (çŸ¥è¯†å›¾è°±è®°å¿†)

**èƒ½åŠ›**:
- æŒä¹…åŒ–çŸ¥è¯†å­˜å‚¨
- å®ä½“å’Œå…³ç³»ç®¡ç†
- è·¨ä¼šè¯è®°å¿†
- çŸ¥è¯†æ£€ç´¢

**æ•°æ®æ¨¡å‹**:
```typescript
// å®ä½“ï¼ˆEntityï¼‰
interface Entity {
  name: string;
  entityType: string;  // ç±»å‹ï¼ˆPerson, Project, Conceptç­‰ï¼‰
  observations: string[];  // è§‚å¯Ÿè®°å½•
}

// å…³ç³»ï¼ˆRelationï¼‰
interface Relation {
  from: string;  // å®ä½“åç§°
  to: string;    // å®ä½“åç§°
  relationType: string;  // å…³ç³»ç±»å‹ï¼ˆuses, implements, depends_onç­‰ï¼‰
}

// è§‚å¯Ÿï¼ˆObservationï¼‰
interface Observation {
  entityName: string;
  contents: string[];  // è§‚å¯Ÿå†…å®¹
}
```

**é€‚ç”¨åœºæ™¯**:
```python
# åœºæ™¯1: é¡¹ç›®ä¸Šä¸‹æ–‡è®°å¿†
# è®°å½•é¡¹ç›®ä¿¡æ¯
create_entities([
  {
    "name": "GEO Platform",
    "entityType": "Project",
    "observations": [
      "ä½¿ç”¨Neo4jä½œä¸ºçŸ¥è¯†å›¾è°±æ•°æ®åº“",
      "åç«¯æ¡†æ¶æ˜¯FastAPI",
      "æ”¯æŒGraph-RAGé—®ç­”"
    ]
  }
])

# åˆ›å»ºå…³ç³»
create_relations([
  {
    "from": "GEO Platform",
    "to": "Neo4j",
    "relationType": "uses"
  }
])

# åœºæ™¯2: æŠ€æœ¯å†³ç­–è®°å½•
# è®°å½•å†³ç­–
add_observations({
  "entityName": "GEO Platform",
  "contents": [
    "2025-10-16: é€‰æ‹©Cytoscape.jsç”¨äºå›¾å¯è§†åŒ–",
    "åŸå› : æ€§èƒ½å¥½ï¼Œæ”¯æŒå¤§è§„æ¨¡å›¾æ¸²æŸ“"
  ]
})

# åœºæ™¯3: è·¨ä¼šè¯æŸ¥è¯¢
# æœç´¢ç›¸å…³çŸ¥è¯†
search_nodes("Neo4j")
# è¿”å›: GEO Platformé¡¹ç›®çš„æ‰€æœ‰Neo4jç›¸å…³ä¿¡æ¯
```

**è‡ªåŠ¨åŒ–å¼€å‘ç”¨æ³•**:
```bash
# Claudeè‡ªåŠ¨ä½¿ç”¨Memoryè®°å½•é¡¹ç›®ä¿¡æ¯
# ä¸‹æ¬¡å¯¹è¯æ—¶å¯ä»¥ç›´æ¥è®¿é—®è¿™äº›ä¿¡æ¯

Session 1:
ç”¨æˆ·: "æˆ‘ä»¬çš„é¡¹ç›®ä½¿ç”¨Neo4j 5.14.0"
Claude: [è‡ªåŠ¨åˆ›å»ºå®ä½“å’Œè§‚å¯Ÿè®°å½•]

Session 2 (æ•°å¤©å):
ç”¨æˆ·: "æˆ‘ä»¬é¡¹ç›®ç”¨çš„æ˜¯å“ªä¸ªç‰ˆæœ¬çš„Neo4jï¼Ÿ"
Claude: [ä»Memoryæ£€ç´¢] "æ‚¨çš„é¡¹ç›®ä½¿ç”¨Neo4j 5.14.0"
```

---

### ğŸŒ Webä¸æµè§ˆå™¨è‡ªåŠ¨åŒ–

#### 3. Puppeteer (æµè§ˆå™¨è‡ªåŠ¨åŒ–)

**èƒ½åŠ›**:
- é¡µé¢å¯¼èˆªå’Œæ¸²æŸ“
- å…ƒç´ äº¤äº’ï¼ˆç‚¹å‡»ã€è¾“å…¥ã€é€‰æ‹©ï¼‰
- æˆªå›¾å’ŒPDFç”Ÿæˆ
- JavaScriptæ‰§è¡Œ
- Cookieå’ŒSessionç®¡ç†

**APIæ–¹æ³•**:
```typescript
// å¯¼èˆªåˆ°URL
puppeteer_navigate({
  url: "https://example.com",
  launchOptions: { headless: true }
})

// æˆªå›¾
puppeteer_screenshot({
  name: "homepage",
  width: 1920,
  height: 1080,
  selector: "#main-content"  // å¯é€‰ï¼Œæˆªå–ç‰¹å®šå…ƒç´ 
})

// ç‚¹å‡»å…ƒç´ 
puppeteer_click({
  selector: "button.submit"
})

// å¡«å†™è¡¨å•
puppeteer_fill({
  selector: "input[name='email']",
  value: "user@example.com"
})

// æ‰§è¡ŒJavaScript
puppeteer_evaluate({
  script: `
    document.querySelector('.notification').remove();
    return document.title;
  `
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: è‡ªåŠ¨åŒ–æµ‹è¯•
"""
å®Œæ•´E2Eæµ‹è¯•æµç¨‹ï¼š
1. æ‰“å¼€åº”ç”¨
2. ç™»å½•
3. åˆ›å»ºæ•°æ®æº
4. æŸ¥çœ‹å›¾è°±
5. éªŒè¯ç»“æœ
6. æˆªå›¾ä¿å­˜
"""

# åœºæ™¯2: ç«å“ç›‘æ§
"""
æ¯æ—¥è‡ªåŠ¨åŒ–æµç¨‹ï¼š
1. è®¿é—®ç«å“ç½‘ç«™
2. æŠ“å–äº§å“ä¿¡æ¯
3. æˆªå›¾å¯¹æ¯”
4. ä¿å­˜åˆ°æ•°æ®åº“
"""

# åœºæ™¯3: å¯è§†åŒ–æ¼”ç¤ºç”Ÿæˆ
"""
è‡ªåŠ¨ç”Ÿæˆäº§å“æ¼”ç¤ºï¼š
1. æ‰“å¼€å„ä¸ªåŠŸèƒ½é¡µé¢
2. æ‰§è¡Œå…³é”®æ“ä½œ
3. æ•è·æ¯ä¸€æ­¥æˆªå›¾
4. ç”Ÿæˆæ¼”ç¤ºæ–‡æ¡£
"""
```

#### 4. Firecrawl (Self-Hosted Webæ•°æ®æå–)

**èƒ½åŠ›**:
- æ™ºèƒ½ç½‘é¡µæŠ“å–
- Markdown/HTMLæå–
- æ‰¹é‡URLå¤„ç†
- ç½‘ç«™åœ°å›¾ç”Ÿæˆ
- æœç´¢å¼•æ“é›†æˆ

**éƒ¨ç½²ä¿¡æ¯**:
- **ä½ç½®**: Docker Desktop
- **APIç«¯ç‚¹**: http://localhost:3002
- **ç®¡ç†ç•Œé¢**: http://localhost:3002/admin/@/queues
- **ç‰¹ç‚¹**: æœ¬åœ°éƒ¨ç½²ï¼Œæ— ä½¿ç”¨é™åˆ¶

**APIæ–¹æ³•**:
```typescript
// å•é¡µæŠ“å–
firecrawl_scrape({
  url: "https://example.com/article",
  formats: ["markdown", "html"],
  onlyMainContent: true
})

// æ‰¹é‡æŠ“å–
firecrawl_batch_scrape({
  urls: [
    "https://example.com/page1",
    "https://example.com/page2"
  ]
})

// ç½‘ç«™æœç´¢
firecrawl_search({
  query: "best mattress reviews",
  limit: 10,
  sources: ["web"]
})

// ç½‘ç«™åœ°å›¾
firecrawl_map({
  url: "https://example.com",
  includeSubdomains: false
})

// æ™ºèƒ½æŠ½å–
firecrawl_extract({
  urls: ["https://example.com/products"],
  schema: {
    type: "object",
    properties: {
      name: { type: "string" },
      price: { type: "number" },
      rating: { type: "number" }
    }
  }
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: ç«å“æ•°æ®é‡‡é›†
workflow = {
  "name": "Daily Competitor Analysis",
  "steps": [
    {
      "action": "firecrawl_search",
      "query": "memory foam mattress reviews 2025",
      "limit": 20
    },
    {
      "action": "firecrawl_batch_scrape",
      "urls": "[ä»æœç´¢ç»“æœè·å–]"
    },
    {
      "action": "save_to_database",
      "target": "mongodb.competitor_data"
    }
  ]
}

# åœºæ™¯2: å†…å®¹ç›‘æ§
"""
ç›‘æ§ç›®æ ‡ç½‘ç«™æ›´æ–°ï¼š
1. ä½¿ç”¨firecrawl_mapè·å–ç½‘ç«™ç»“æ„
2. å®šæœŸæŠ“å–å…³é”®é¡µé¢
3. å¯¹æ¯”å†…å®¹å˜åŒ–
4. å‘é€é€šçŸ¥
"""

# åœºæ™¯3: æ•°æ®å¯¼å…¥GEOç³»ç»Ÿ
"""
è‡ªåŠ¨åŒ–æ•°æ®æµï¼š
1. firecrawl_scrapeæŠ“å–åŸå§‹å†…å®¹
2. æ¸…æ´—å’Œæ ¼å¼åŒ–
3. InfraNodusåˆ†æ
4. Neo4jå¯¼å…¥
"""
```

#### 5. Chrome DevTools MCP

**èƒ½åŠ›**:
- ç½‘ç»œè¯·æ±‚ç›‘æ§
- æ€§èƒ½åˆ†æ
- Consoleæ—¥å¿—æ•è·
- DOMæ£€æŸ¥
- JavaScriptè°ƒè¯•

**ä½¿ç”¨åœºæ™¯**:
```python
# åœºæ™¯1: æ€§èƒ½åˆ†æ
"""
åˆ†æé¡µé¢åŠ è½½æ€§èƒ½ï¼š
1. æ‰“å¼€é¡µé¢
2. æ•è·æ€§èƒ½æŒ‡æ ‡
3. è¯†åˆ«ç“¶é¢ˆ
4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
"""

# åœºæ™¯2: APIè°ƒç”¨åˆ†æ
"""
ç›‘æ§APIè¯·æ±‚ï¼š
1. è®°å½•æ‰€æœ‰ç½‘ç»œè¯·æ±‚
2. åˆ†æè¯·æ±‚æ—¶é—´
3. æ£€æŸ¥å“åº”æ•°æ®
4. ä¼˜åŒ–APIè°ƒç”¨
"""
```

---

### ğŸ’¾ æ•°æ®åº“æœåŠ¡å™¨

#### 6. Neo4j (å›¾æ•°æ®åº“)

**éƒ¨ç½²ä¿¡æ¯**:
- **å®¹å™¨**: neo4j-claude-mcp
- **ç«¯å£**: Bolt: 7688, HTTP: 7475
- **å‡­è¯**: neo4j / claude_neo4j_2025
- **æµè§ˆå™¨**: http://localhost:7475

**èƒ½åŠ›**:
```typescript
// æ‰§è¡ŒCypheræŸ¥è¯¢
execute_query({
  query: `
    MATCH (k:Keyword)-[:CO_OCCURS_WITH]->(k2:Keyword)
    WHERE k.name = $keyword
    RETURN k2.name AS related, count(*) AS frequency
    ORDER BY frequency DESC
    LIMIT 10
  `,
  params: { keyword: "cooling_gel" }
})

// åˆ›å»ºèŠ‚ç‚¹
create_node({
  label: "Keyword",
  properties: {
    name: "memory_foam",
    frequency: 142,
    betweenness: 0.85
  }
})

// åˆ›å»ºå…³ç³»
create_relationship({
  fromNodeId: 123,
  toNodeId: 456,
  type: "CO_OCCURS_WITH",
  properties: { weight: 0.75 }
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: è‡ªåŠ¨åŒ–å›¾è°±æ„å»º
"""
æ•°æ®å¯¼å…¥æµç¨‹ï¼š
1. ä»Firecrawlè·å–æ–‡æœ¬
2. InfraNodusåˆ†æç”Ÿæˆå…±ç°ç½‘ç»œ
3. Neo4jæ‰¹é‡å¯¼å…¥èŠ‚ç‚¹å’Œå…³ç³»
4. åˆ›å»ºç´¢å¼•å’Œçº¦æŸ
5. è¿è¡Œå›¾ç®—æ³•ï¼ˆPageRankã€ç¤¾åŒºå‘ç°ï¼‰
"""

# åœºæ™¯2: å®æ—¶æŸ¥è¯¢API
"""
Graph-RAGé—®ç­”ç³»ç»Ÿï¼š
1. æ¥æ”¶ç”¨æˆ·é—®é¢˜
2. Neo4jæ£€ç´¢ç›¸å…³å­å›¾
3. ç»„è£…ä¸Šä¸‹æ–‡
4. LLMç”Ÿæˆç­”æ¡ˆ
5. è¿½è¸ªå¼•ç”¨æ¥æº
"""

# åœºæ™¯3: å®šæ—¶åˆ†æä»»åŠ¡
"""
æ¯æ—¥ç»“æ„æ´åˆ†æï¼š
1. Celeryå®šæ—¶è§¦å‘
2. Neo4jæ‰§è¡Œç»“æ„æ´æ£€æµ‹ç®—æ³•
3. è¯†åˆ«å†…å®¹æœºä¼š
4. ç”Ÿæˆæç¤ºè¯
5. Slacké€šçŸ¥å›¢é˜Ÿ
"""
```

#### 7. PostgreSQL (å…³ç³»æ•°æ®åº“)

**éƒ¨ç½²ä¿¡æ¯**:
- **å®¹å™¨**: postgres-claude-mcp
- **ç«¯å£**: 5437
- **å‡­è¯**: claude / claude_dev_2025
- **æ•°æ®åº“**: claude_dev

**èƒ½åŠ›**:
- CRUDæ“ä½œ
- å¤æ‚æŸ¥è¯¢ï¼ˆJOINã€å­æŸ¥è¯¢ï¼‰
- äº‹åŠ¡ç®¡ç†
- å…¨æ–‡æœç´¢
- JSONå­—æ®µæ”¯æŒ

**Schemaè®¾è®¡ç¤ºä¾‹**:
```sql
-- ç”¨æˆ·è¡¨
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email VARCHAR(255) UNIQUE NOT NULL,
  password_hash VARCHAR(255) NOT NULL,
  role VARCHAR(50) NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);

-- æ•°æ®æºè¡¨
CREATE TABLE data_sources (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id),
  name VARCHAR(255) NOT NULL,
  type VARCHAR(50) NOT NULL,  -- WEB, API, FILE
  config JSONB,
  schedule VARCHAR(100),
  last_run TIMESTAMP,
  status VARCHAR(50)
);

-- å¯¼å…¥ä»»åŠ¡è¡¨
CREATE TABLE imports (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_id UUID REFERENCES data_sources(id),
  started_at TIMESTAMP DEFAULT NOW(),
  completed_at TIMESTAMP,
  records_processed INTEGER,
  records_imported INTEGER,
  status VARCHAR(50),
  errors JSONB
);
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ
"""
å®Œæ•´ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸï¼š
1. æ³¨å†Œ â†’ INSERT INTO users
2. ç™»å½•éªŒè¯ â†’ SELECT + passwordéªŒè¯
3. æƒé™æ£€æŸ¥ â†’ JOIN users + roles
4. å®¡è®¡æ—¥å¿— â†’ INSERT INTO audit_logs
"""

# åœºæ™¯2: æ•°æ®æºè°ƒåº¦
"""
è‡ªåŠ¨åŒ–è°ƒåº¦ç³»ç»Ÿï¼š
1. Celery BeatæŸ¥è¯¢å¾…æ‰§è¡Œçš„æ•°æ®æº
2. åˆ›å»ºå¯¼å…¥ä»»åŠ¡è®°å½•
3. æ‰§è¡ŒæŠ“å–
4. æ›´æ–°ä»»åŠ¡çŠ¶æ€
5. è®°å½•ç»Ÿè®¡ä¿¡æ¯
"""
```

#### 8. MongoDB (æ–‡æ¡£æ•°æ®åº“)

**éƒ¨ç½²ä¿¡æ¯**:
- **å®¹å™¨**: mongodb-claude-mcp
- **ç«¯å£**: 27018
- **å‡­è¯**: claude / claude_mongo_2025
- **æ•°æ®åº“**: claude_dev

**èƒ½åŠ›**:
```typescript
// æ’å…¥æ–‡æ¡£
insert_many({
  database: "claude_dev",
  collection: "audit_logs",
  documents: [
    {
      user_id: "123",
      action: "DELETE",
      resource: "Entity",
      timestamp: new Date()
    }
  ]
})

// æŸ¥è¯¢
find({
  database: "claude_dev",
  collection: "audit_logs",
  filter: { user_id: "123" },
  sort: { timestamp: -1 },
  limit: 10
})

// èšåˆ
aggregate({
  database: "claude_dev",
  collection: "audit_logs",
  pipeline: [
    { $match: { action: "DELETE" } },
    { $group: { _id: "$user_id", count: { $sum: 1 } } },
    { $sort: { count: -1 } }
  ]
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
"""
å®Œæ•´å®¡è®¡è¿½è¸ªï¼š
1. APIä¸­é—´ä»¶æ‹¦æˆªæ‰€æœ‰è¯·æ±‚
2. è®°å½•æ“ä½œè¯¦æƒ…åˆ°MongoDB
3. å®šæœŸèšåˆåˆ†æ
4. ç”Ÿæˆå®‰å…¨æŠ¥å‘Š
"""

# åœºæ™¯2: åˆ†ææ•°æ®å­˜å‚¨
"""
ç½‘ç«™åˆ†ææµç¨‹ï¼š
1. ç”¨æˆ·è¡Œä¸ºäº‹ä»¶ â†’ MongoDB
2. å®æ—¶èšåˆç»Ÿè®¡
3. Dashboardå±•ç¤º
4. å®šæœŸå½’æ¡£åˆ°PostgreSQL
"""

# åœºæ™¯3: æ—¥å¿—æ”¶é›†
"""
é›†ä¸­å¼æ—¥å¿—ç®¡ç†ï¼š
1. æ‰€æœ‰æœåŠ¡æ—¥å¿— â†’ MongoDB
2. ç»“æ„åŒ–å­˜å‚¨
3. å…¨æ–‡æœç´¢
4. å‘Šè­¦è§„åˆ™
"""
```

#### 9. Redis (ç¼“å­˜å’Œé˜Ÿåˆ—)

**éƒ¨ç½²ä¿¡æ¯**:
- **å®¹å™¨**: redis-claude-mcp
- **ç«¯å£**: 6382
- **å¯†ç **: claude_redis_2025

**èƒ½åŠ›**:
```typescript
// è®¾ç½®é”®å€¼
set({
  key: "user:123:profile",
  value: JSON.stringify({ name: "Alice", role: "admin" }),
  expireSeconds: 3600  // 1å°æ—¶è¿‡æœŸ
})

// è·å–å€¼
get({
  key: "user:123:profile"
})

// åˆ é™¤
delete({
  key: "user:123:profile"
})

// åˆ—è¡¨æ“ä½œ
list({
  pattern: "user:*"  // åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·ç›¸å…³çš„é”®
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: APIå“åº”ç¼“å­˜
"""
ç¼“å­˜ç­–ç•¥ï¼š
1. è¯·æ±‚åˆ°è¾¾ â†’ æ£€æŸ¥Redis
2. ç¼“å­˜å‘½ä¸­ â†’ ç›´æ¥è¿”å›
3. ç¼“å­˜æœªå‘½ä¸­ â†’ æŸ¥è¯¢æ•°æ®åº“
4. ç»“æœå†™å…¥Redisï¼ˆå¸¦è¿‡æœŸæ—¶é—´ï¼‰
5. è¿”å›å“åº”
"""

# åœºæ™¯2: Celeryä»»åŠ¡é˜Ÿåˆ—
"""
å¼‚æ­¥ä»»åŠ¡å¤„ç†ï¼š
1. APIæ¥æ”¶è¯·æ±‚ â†’ ä»»åŠ¡å…¥é˜ŸRedis
2. Celery Workerä»é˜Ÿåˆ—å–ä»»åŠ¡
3. æ‰§è¡Œä»»åŠ¡ï¼ˆæ•°æ®é‡‡é›†ã€åˆ†æç­‰ï¼‰
4. ç»“æœå†™å›Redis
5. å‰ç«¯è½®è¯¢æˆ–WebSocketæ¨é€ç»“æœ
"""

# åœºæ™¯3: ä¼šè¯ç®¡ç†
"""
ç”¨æˆ·ä¼šè¯å­˜å‚¨ï¼š
1. ç”¨æˆ·ç™»å½• â†’ JWT Token
2. Tokenè¯¦æƒ…å­˜å‚¨Redis
3. æ¯æ¬¡è¯·æ±‚éªŒè¯Token
4. Tokenè¿‡æœŸè‡ªåŠ¨æ¸…ç†
"""

# åœºæ™¯4: é€Ÿç‡é™åˆ¶
"""
APIé™æµï¼š
1. è¯†åˆ«ç”¨æˆ·ï¼ˆIP/User IDï¼‰
2. Redisè®¡æ•°å™¨ + è¿‡æœŸæ—¶é—´
3. è¶…è¿‡é™åˆ¶ â†’ æ‹’ç»è¯·æ±‚
4. å®šæœŸé‡ç½®è®¡æ•°
"""
```

#### 10. SQLite Explorer (è½»é‡çº§æ•°æ®åº“)

**éƒ¨ç½²ä¿¡æ¯**:
- **ä½ç½®**: /Users/cavin/sqlite-explorer-fastmcp-mcp-server/
- **æ•°æ®åº“**: /Users/cavin/test.db
- **ç‰¹ç‚¹**: åªè¯»è®¿é—®ï¼Œå®‰å…¨æ¢ç´¢

**ä½¿ç”¨åœºæ™¯**:
```python
# åœºæ™¯1: æœ¬åœ°å¼€å‘æ•°æ®åº“
"""
è½»é‡çº§å¼€å‘ç¯å¢ƒï¼š
1. å¿«é€ŸåŸå‹å¼€å‘
2. æµ‹è¯•æ•°æ®éªŒè¯
3. æœ¬åœ°æ•°æ®åˆ†æ
"""

# åœºæ™¯2: é…ç½®æ–‡ä»¶å­˜å‚¨
"""
åº”ç”¨é…ç½®ç®¡ç†ï¼š
1. ç»“æ„åŒ–é…ç½®å­˜å‚¨
2. ç‰ˆæœ¬æ§åˆ¶å‹å¥½
3. SQLæŸ¥è¯¢é…ç½®
"""
```

#### 11. Prisma (ç°ä»£ORM)

**èƒ½åŠ›**:
- ç±»å‹å®‰å…¨çš„æ•°æ®åº“æ“ä½œ
- è‡ªåŠ¨è¿ç§»ç®¡ç†
- æ•°æ®åº“æ¨¡å¼å¯è§†åŒ–
- å¤šæ•°æ®åº“æ”¯æŒ

**Schemaç¤ºä¾‹**:
```prisma
// schema.prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

model User {
  id        String   @id @default(uuid())
  email     String   @unique
  name      String?
  role      Role     @default(VIEWER)
  createdAt DateTime @default(now())

  dataSources DataSource[]
}

model DataSource {
  id        String   @id @default(uuid())
  name      String
  type      SourceType
  config    Json
  userId    String
  user      User     @relation(fields: [userId], references: [id])

  imports   Import[]
}

enum Role {
  ADMIN
  CONTENT_MANAGER
  ANALYST
  EDITOR
  VIEWER
}

enum SourceType {
  WEB
  API
  FILE
  DATABASE
}
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: æ•°æ®åº“è¿ç§»è‡ªåŠ¨åŒ–
"""
Schemaæ¼”åŒ–æµç¨‹ï¼š
1. ä¿®æ”¹schema.prisma
2. è¿è¡Œprisma migrate dev
3. ç”Ÿæˆè¿ç§»æ–‡ä»¶
4. åº”ç”¨åˆ°æ•°æ®åº“
5. æ›´æ–°Prisma Client
"""

# åœºæ™¯2: ç±»å‹å®‰å…¨çš„CRUD
"""
ç±»å‹å®‰å…¨å¼€å‘ï¼š
1. Prismaç”ŸæˆTypeScriptç±»å‹
2. è‡ªåŠ¨å®Œæˆå’Œç±»å‹æ£€æŸ¥
3. è¿è¡Œæ—¶ç±»å‹éªŒè¯
4. å‡å°‘è¿è¡Œæ—¶é”™è¯¯
"""
```

---

### ğŸ¨ å‰ç«¯ä¸UI

#### 12. Magic UI (AIé©±åŠ¨çš„UIç»„ä»¶)

**èƒ½åŠ›**:
- è‡ªåŠ¨ç”ŸæˆReactç»„ä»¶
- å“åº”å¼è®¾è®¡
- åŠ¨ç”»å’Œè¿‡æ¸¡æ•ˆæœ
- ä¸»é¢˜å®šåˆ¶

**ç»„ä»¶ç±»åˆ«**:
```typescript
// 1. åŸºç¡€ç»„ä»¶
getComponents()
// è¿”å›: marquee, terminal, hero-video-dialog, bento-grid,
//       animated-list, dock, globe, tweet-card, etc.

// 2. è®¾å¤‡æ¨¡æ‹Ÿ
getDeviceMocks()
// è¿”å›: safari, iphone-15-pro, android

// 3. ç‰¹æ•ˆç»„ä»¶
getSpecialEffects()
// è¿”å›: animated-beam, border-beam, shine-border,
//       magic-card, meteors, particles, cool-mode

// 4. æ–‡æœ¬åŠ¨ç”»
getTextAnimations()
// è¿”å›: text-animate, aurora-text, number-ticker,
//       animated-shiny-text, word-rotate, typing-animation

// 5. æŒ‰é’®ç»„ä»¶
getButtons()
// è¿”å›: rainbow-button, shimmer-button, shiny-button,
//       interactive-hover-button, pulsating-button

// 6. èƒŒæ™¯ç»„ä»¶
getBackgrounds()
// è¿”å›: warp-background, flickering-grid, animated-grid-pattern,
//       retro-grid, ripple, dot-pattern
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: å¿«é€ŸåŸå‹å¼€å‘
"""
UIå¿«é€Ÿè¿­ä»£ï¼š
1. æè¿°UIéœ€æ±‚
2. Magic UIç”Ÿæˆç»„ä»¶ä»£ç 
3. é›†æˆåˆ°é¡¹ç›®
4. é¢„è§ˆå’Œè°ƒæ•´
"""

# åœºæ™¯2: è¥é”€é¡µé¢ç”Ÿæˆ
"""
è‡ªåŠ¨åŒ–é¡µé¢åˆ›å»ºï¼š
1. è¾“å…¥äº§å“ä¿¡æ¯
2. é€‰æ‹©æ¨¡æ¿å’Œç»„ä»¶
3. Magic UIç»„è£…é¡µé¢
4. å¯¼å‡ºä»£ç 
"""

# åœºæ™¯3: è®¾è®¡ç³»ç»Ÿæ„å»º
"""
ä¸€è‡´æ€§UIç»„ä»¶åº“ï¼š
1. å®šä¹‰è®¾è®¡è§„èŒƒ
2. Magic UIç”Ÿæˆç»„ä»¶
3. æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
4. Storybooké›†æˆ
"""
```

#### 13. Filesystem (é«˜çº§æ–‡ä»¶æ“ä½œ)

**èƒ½åŠ›**:
- è¯»å†™æ–‡ä»¶
- ç›®å½•æ“ä½œ
- æ–‡ä»¶æœç´¢
- æ‰¹é‡æ“ä½œ
- æƒé™ç®¡ç†

**APIæ–¹æ³•**:
```typescript
// è¯»å–æ–‡ä»¶
read_text_file({
  path: "/path/to/file.txt",
  head: 100  // åªè¯»å‰100è¡Œ
})

// æ‰¹é‡è¯»å–
read_multiple_files({
  paths: ["/path/file1.txt", "/path/file2.txt"]
})

// å†™å…¥æ–‡ä»¶
write_file({
  path: "/path/to/output.txt",
  content: "Hello, World!"
})

// ç¼–è¾‘æ–‡ä»¶
edit_file({
  path: "/path/to/file.txt",
  edits: [
    {
      oldText: "old value",
      newText: "new value"
    }
  ]
})

// æœç´¢æ–‡ä»¶
search_files({
  path: "/project",
  pattern: "*.ts",
  excludePatterns: ["node_modules", "dist"]
})

// ç›®å½•æ ‘
directory_tree({
  path: "/project"
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: ä»£ç ç”Ÿæˆè‡ªåŠ¨åŒ–
"""
æ‰¹é‡ç”Ÿæˆä»£ç æ–‡ä»¶ï¼š
1. è¯»å–æ¨¡æ¿æ–‡ä»¶
2. æ›¿æ¢å˜é‡
3. æ‰¹é‡å†™å…¥æ–‡ä»¶
4. åˆ›å»ºç›®å½•ç»“æ„
"""

# åœºæ™¯2: é…ç½®æ–‡ä»¶ç®¡ç†
"""
å¤šç¯å¢ƒé…ç½®ï¼š
1. è¯»å–åŸºç¡€é…ç½®
2. æ ¹æ®ç¯å¢ƒå˜é‡è°ƒæ•´
3. å†™å…¥ç‰¹å®šç¯å¢ƒé…ç½®
4. éªŒè¯é…ç½®æ­£ç¡®æ€§
"""

# åœºæ™¯3: æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
"""
APIæ–‡æ¡£ç”Ÿæˆï¼š
1. æ‰«ææºä»£ç 
2. æå–æ³¨é‡Šå’Œç±»å‹
3. ç”ŸæˆMarkdownæ–‡æ¡£
4. æ›´æ–°README
"""
```

---

### ğŸ”§ ç‰ˆæœ¬æ§åˆ¶ä¸DevOps

#### 14. GitHub (ä»£ç æ‰˜ç®¡)

**èƒ½åŠ›**:
```typescript
// ä»“åº“æ“ä½œ
create_repository({
  name: "geo-platform",
  description: "GEO Knowledge Graph System",
  private: true,
  autoInit: true
})

fork_repository({
  owner: "original-owner",
  repo: "project",
  organization: "my-org"  // å¯é€‰
})

// æ–‡ä»¶æ“ä½œ
get_file_contents({
  owner: "my-org",
  repo: "geo-platform",
  path: "src/main.py",
  branch: "develop"
})

create_or_update_file({
  owner: "my-org",
  repo: "geo-platform",
  path: "docs/API.md",
  content: "# API Documentation",
  message: "Update API docs",
  branch: "develop"
})

push_files({
  owner: "my-org",
  repo: "geo-platform",
  branch: "develop",
  files: [
    { path: "file1.py", content: "..." },
    { path: "file2.py", content: "..." }
  ],
  message: "Add new features"
})

// Issueç®¡ç†
create_issue({
  owner: "my-org",
  repo: "geo-platform",
  title: "Add Graph-RAG support",
  body: "Implement Graph-RAG question answering",
  labels: ["enhancement", "high-priority"],
  assignees: ["developer1"]
})

list_issues({
  owner: "my-org",
  repo: "geo-platform",
  state: "open",
  labels: ["bug"]
})

// Pull Request
create_pull_request({
  owner: "my-org",
  repo: "geo-platform",
  title: "Feature: Graph-RAG implementation",
  head: "feature/graph-rag",
  base: "develop",
  body: "Implements Graph-RAG with Neo4j integration"
})

merge_pull_request({
  owner: "my-org",
  repo: "geo-platform",
  pull_number: 42,
  merge_method: "squash"
})

// ä»£ç æœç´¢
search_code({
  q: "def find_structure_holes repo:my-org/geo-platform"
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: è‡ªåŠ¨åŒ–å‘å¸ƒæµç¨‹
"""
Release Automation:
1. æ£€æµ‹ç‰ˆæœ¬å·å˜æ›´
2. åˆ›å»ºreleaseåˆ†æ”¯
3. æ›´æ–°CHANGELOG
4. æ¨é€ä»£ç 
5. åˆ›å»ºGitHub Release
6. è§¦å‘CI/CDéƒ¨ç½²
"""

# åœºæ™¯2: Issueè‡ªåŠ¨åŒ–ç®¡ç†
"""
Issue Triage Bot:
1. ç›‘å¬æ–°Issue
2. åˆ†æå†…å®¹ï¼ˆä½¿ç”¨LLMï¼‰
3. è‡ªåŠ¨æ‰“æ ‡ç­¾
4. åˆ†é…ç»™åˆé€‚çš„å¼€å‘è€…
5. æ·»åŠ æ¨¡æ¿å›å¤
"""

# åœºæ™¯3: PR ReviewåŠ©æ‰‹
"""
Automated Code Review:
1. æ£€æµ‹æ–°PR
2. è·å–æ”¹åŠ¨çš„æ–‡ä»¶
3. ä½¿ç”¨LLMåˆ†æä»£ç 
4. æå‡ºæ”¹è¿›å»ºè®®
5. è‡ªåŠ¨è¯„è®ºåˆ°PR
"""

# åœºæ™¯4: æ–‡æ¡£åŒæ­¥
"""
Docs Sync:
1. ç›‘å¬ä»£ç å˜æ›´
2. æå–APIå˜æ›´
3. è‡ªåŠ¨æ›´æ–°æ–‡æ¡£
4. æäº¤PRåˆ°docsä»“åº“
"""
```

#### 15. GitLab (æ›¿ä»£æ–¹æ¡ˆ)

**èƒ½åŠ›**: ä¸GitHubç±»ä¼¼ï¼Œæ”¯æŒï¼š
- ä»“åº“ç®¡ç†
- CI/CD Pipeline
- Issueå’ŒMRç®¡ç†
- Wikiç®¡ç†

**GitLabç‰¹è‰²**:
```python
# GitLab CI/CDé›†æˆ
"""
.gitlab-ci.ymlè‡ªåŠ¨ç”Ÿæˆï¼š
1. åˆ†æé¡¹ç›®ç±»å‹
2. ç”ŸæˆCIé…ç½®
3. æ¨é€åˆ°ä»“åº“
4. Pipelineè‡ªåŠ¨è¿è¡Œ
"""
```

#### 16. n8n (å·¥ä½œæµè‡ªåŠ¨åŒ–)

**èƒ½åŠ›**:
- å¯è§†åŒ–å·¥ä½œæµç¼–æ’
- 300+ é›†æˆèŠ‚ç‚¹
- Webhookè§¦å‘
- å®šæ—¶ä»»åŠ¡
- æ¡ä»¶åˆ†æ”¯
- å¾ªç¯å’Œè¿­ä»£

**APIæ–¹æ³•**:
```typescript
// åˆ—å‡ºå·¥ä½œæµ
list_workflows({
  active: true
})

// è·å–å·¥ä½œæµ
get_workflow({
  workflowId: "123"
})

// åˆ›å»ºå·¥ä½œæµ
create_workflow({
  name: "Daily Data Sync",
  nodes: [
    {
      type: "n8n-nodes-base.cron",
      parameters: { rule: "0 2 * * *" }
    },
    {
      type: "n8n-nodes-base.httpRequest",
      parameters: {
        url: "https://api.example.com/data",
        method: "GET"
      }
    }
  ],
  connections: { ... }
})

// è§¦å‘å·¥ä½œæµ
run_webhook({
  workflowName: "process-data",
  data: { input: "value" }
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: æ•°æ®åŒæ­¥è‡ªåŠ¨åŒ–
"""
Multi-Source Data Sync:
n8n Workflow:
  â”œâ”€ Trigger: Cron (æ¯å¤©2AM)
  â”œâ”€ HTTP Request: æŠ“å–ç«å“æ•°æ®
  â”œâ”€ Code: æ•°æ®æ¸…æ´—
  â”œâ”€ MongoDB: ä¿å­˜åŸå§‹æ•°æ®
  â”œâ”€ HTTP Request: è°ƒç”¨InfraNodus API
  â”œâ”€ Neo4j: å¯¼å…¥å›¾æ•°æ®
  â””â”€ Slack: å‘é€å®Œæˆé€šçŸ¥
"""

# åœºæ™¯2: å†…å®¹å‘å¸ƒæµæ°´çº¿
"""
Content Publishing Pipeline:
n8n Workflow:
  â”œâ”€ Webhook: æ¥æ”¶æ–°å†…å®¹
  â”œâ”€ IF: æ£€æŸ¥Citation Score > 0.7
  â”‚   â”œâ”€ Yes:
  â”‚   â”‚   â”œâ”€ WordPress: å‘å¸ƒæ–‡ç« 
  â”‚   â”‚   â”œâ”€ Twitter: å‘æ¨æ–‡
  â”‚   â”‚   â”œâ”€ LinkedIn: å‘å¸–
  â”‚   â”‚   â””â”€ Slack: æˆåŠŸé€šçŸ¥
  â”‚   â””â”€ No:
  â”‚       â””â”€ Slack: è¯·æ±‚äººå·¥å®¡æ ¸
"""

# åœºæ™¯3: ç›‘æ§å‘Šè­¦ç³»ç»Ÿ
"""
Monitoring and Alerting:
n8n Workflow:
  â”œâ”€ Trigger: Cron (æ¯5åˆ†é’Ÿ)
  â”œâ”€ HTTP Request: å¥åº·æ£€æŸ¥API
  â”œâ”€ Code: åˆ†æå“åº”
  â”œâ”€ IF: æ£€æµ‹å¼‚å¸¸
  â”‚   â”œâ”€ PagerDuty: åˆ›å»ºäº‹ä»¶
  â”‚   â”œâ”€ Slack: å‘é€å‘Šè­¦
  â”‚   â””â”€ Email: é€šçŸ¥è¿ç»´å›¢é˜Ÿ
  â””â”€ MongoDB: è®°å½•æ£€æŸ¥ç»“æœ
"""
```

---

### ğŸ“Š åä½œä¸é€šçŸ¥

#### 17. Notion (çŸ¥è¯†åº“)

**èƒ½åŠ›**:
```typescript
// æŸ¥è¯¢æ•°æ®åº“
post_database_query({
  database_id: "abc123",
  filter: {
    property: "Status",
    select: { equals: "In Progress" }
  },
  sorts: [
    { property: "Priority", direction: "descending" }
  ]
})

// åˆ›å»ºé¡µé¢
post_page({
  parent: { page_id: "parent-page-id" },
  properties: {
    title: [
      {
        text: { content: "New Task" }
      }
    ]
  }
})

// æ›´æ–°é¡µé¢
patch_page({
  page_id: "page-123",
  properties: {
    Status: { select: { name: "Completed" } }
  }
})

// æ·»åŠ å†…å®¹å—
patch_block_children({
  block_id: "page-123",
  children: [
    {
      type: "paragraph",
      paragraph: {
        rich_text: [
          { text: { content: "This is a paragraph" } }
        ]
      }
    }
  ]
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: é¡¹ç›®æ–‡æ¡£è‡ªåŠ¨åŒ–
"""
Documentation Sync:
1. ä»£ç æ³¨é‡Šæå–
2. ç”ŸæˆAPIæ–‡æ¡£
3. åŒæ­¥åˆ°Notion
4. æ›´æ–°ç›®å½•ç»“æ„
"""

# åœºæ™¯2: ä»»åŠ¡ç®¡ç†é›†æˆ
"""
Task Tracking:
1. GitHub Issueåˆ›å»º â†’ Notion Task
2. PRåˆå¹¶ â†’ æ›´æ–°TaskçŠ¶æ€
3. æ¯æ—¥åŒæ­¥è¿›åº¦
4. ç”Ÿæˆå‘¨æŠ¥
"""

# åœºæ™¯3: çŸ¥è¯†åº“æ„å»º
"""
Knowledge Base:
1. æ”¶é›†æŠ€æœ¯æ–‡æ¡£
2. æ•´ç†åˆ†ç±»
3. åˆ›å»ºNotioné¡µé¢
4. æ·»åŠ æ ‡ç­¾å’Œå…³è”
"""
```

#### 18. Slack (å›¢é˜Ÿé€šä¿¡)

**èƒ½åŠ›**:
- å‘é€æ¶ˆæ¯
- åˆ›å»ºé¢‘é“
- æ–‡ä»¶ä¸Šä¼ 
- äº¤äº’å¼æ¶ˆæ¯ï¼ˆæŒ‰é’®ã€èœå•ï¼‰
- Boté›†æˆ

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: å®æ—¶é€šçŸ¥ç³»ç»Ÿ
"""
Event Notifications:
- æ•°æ®å¯¼å…¥å®Œæˆ â†’ #data-team
- ç»“æ„æ´å‘ç° â†’ #content-team
- ç³»ç»Ÿå‘Šè­¦ â†’ #ops-team
- PRéœ€è¦Review â†’ #dev-team
"""

# åœºæ™¯2: ChatOps
"""
Slack Bot Commands:
/deploy production â†’ è§¦å‘éƒ¨ç½²
/status â†’ æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
/analyze gap-123 â†’ åˆ†æç‰¹å®šç»“æ„æ´
/generate prompt-456 â†’ ç”Ÿæˆå†…å®¹
"""

# åœºæ™¯3: å®¡æ‰¹æµç¨‹
"""
Approval Workflow:
1. å†…å®¹ç”Ÿæˆå®Œæˆ
2. Slackå‘é€é¢„è§ˆå’ŒæŒ‰é’®
3. å®¡æ‰¹äººç‚¹å‡»æ‰¹å‡†/æ‹’ç»
4. è§¦å‘å¯¹åº”æ“ä½œ
5. ç»“æœé€šçŸ¥
"""
```

#### 19. Feishu/é£ä¹¦ (ä¼ä¸šåä½œ)

**èƒ½åŠ›**:
```typescript
// æ–‡æ¡£æ“ä½œ
create_feishu_document({
  title: "GEOç³»ç»Ÿå‘¨æŠ¥",
  folderToken: "folder-token"
})

get_feishu_document_blocks({
  documentId: "doc-id"
})

batch_create_feishu_blocks({
  documentId: "doc-id",
  parentBlockId: "block-id",
  index: 0,
  blocks: [
    {
      blockType: "heading1",
      options: {
        heading: {
          level: 1,
          content: "ç³»ç»ŸçŠ¶æ€"
        }
      }
    },
    {
      blockType: "text",
      options: {
        text: {
          textStyles: [
            { text: "å¥åº·åˆ†æ•°: ", style: { bold: true } },
            { text: "80%", style: { text_color: 5 } }
          ]
        }
      }
    }
  ]
})

// è¡¨æ ¼åˆ›å»º
create_feishu_table({
  documentId: "doc-id",
  parentBlockId: "block-id",
  index: 0,
  tableConfig: {
    columnSize: 3,
    rowSize: 5,
    cells: [
      {
        coordinate: { row: 0, column: 0 },
        content: {
          blockType: "text",
          options: { text: { textStyles: [{ text: "æŒ‡æ ‡" }] } }
        }
      }
    ]
  }
})

// å›¾è¡¨åˆ›å»ºï¼ˆMermaidï¼‰
batch_create_feishu_blocks({
  blocks: [
    {
      blockType: "mermaid",
      options: {
        mermaid: {
          code: `
            graph TD
            A[æ•°æ®é‡‡é›†] --> B[åˆ†æ]
            B --> C[å†…å®¹ç”Ÿæˆ]
          `
        }
      }
    }
  ]
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ
"""
Weekly Report to Feishu:
1. æ”¶é›†ç³»ç»Ÿæ•°æ®
2. ç”Ÿæˆç»Ÿè®¡åˆ†æ
3. åˆ›å»ºé£ä¹¦æ–‡æ¡£
4. æ·»åŠ è¡¨æ ¼å’Œå›¾è¡¨
5. @ç›¸å…³äººå‘˜
"""

# åœºæ™¯2: é¡¹ç›®æ–‡æ¡£ç®¡ç†
"""
Documentation System:
1. ä»£ç å˜æ›´ â†’ æ–‡æ¡£æ›´æ–°
2. APIå˜æ›´ â†’ é£ä¹¦æ–‡æ¡£åŒæ­¥
3. æ¶æ„å›¾ â†’ Mermaidæ¸²æŸ“
4. ç‰ˆæœ¬å†å² â†’ æ–‡æ¡£å½’æ¡£
"""

# åœºæ™¯3: åä½œå·¥ä½œæµ
"""
Collaborative Review:
1. å†…å®¹ç”Ÿæˆå®Œæˆ
2. åˆ›å»ºé£ä¹¦æ–‡æ¡£
3. åˆ†äº«ç»™å›¢é˜Ÿ
4. æ”¶é›†è¯„è®º
5. ç‰ˆæœ¬è¿­ä»£
"""
```

---

### ğŸ” ç›‘æ§ä¸è°ƒè¯•

#### 20. Sentry (é”™è¯¯è¿½è¸ª)

**èƒ½åŠ›**:
```typescript
// æœç´¢ç»„ç»‡
find_organizations({
  query: "my-company"
})

// æœç´¢é¡¹ç›®
find_projects({
  organizationSlug: "my-company",
  query: "geo-platform"
})

// è·å–Issueè¯¦æƒ…
get_issue_details({
  organizationSlug: "my-company",
  issueId: "GEO-PLATFORM-123"
})

// æœç´¢Issues
search_issues({
  organizationSlug: "my-company",
  naturalLanguageQuery: "unhandled errors in last 24 hours"
})

// æœç´¢Events
search_events({
  organizationSlug: "my-company",
  naturalLanguageQuery: "how many 500 errors today"
})

// AIåˆ†æIssue
analyze_issue_with_seer({
  issueUrl: "https://sentry.io/issues/123",
  instruction: "æ‰¾å‡ºæ ¹æœ¬åŸå› å¹¶æä¾›ä¿®å¤å»ºè®®"
})
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: æ™ºèƒ½é”™è¯¯è¯Šæ–­
"""
Error Analysis Pipeline:
1. Sentryæ£€æµ‹åˆ°æ–°é”™è¯¯
2. analyze_issue_with_seeråˆ†æ
3. ç”Ÿæˆä¿®å¤å»ºè®®
4. åˆ›å»ºGitHub Issue
5. åˆ†é…ç»™ç›¸å…³å¼€å‘è€…
"""

# åœºæ™¯2: é”™è¯¯è¶‹åŠ¿åˆ†æ
"""
Error Trend Monitoring:
1. search_eventsæŸ¥è¯¢é”™è¯¯ç»Ÿè®¡
2. å¯¹æ¯”å†å²æ•°æ®
3. è¯†åˆ«å¼‚å¸¸è¶‹åŠ¿
4. Slackå‘Šè­¦é€šçŸ¥
5. ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

# åœºæ™¯3: Release Healthç›‘æ§
"""
Release Monitoring:
1. æ–°ç‰ˆæœ¬éƒ¨ç½²
2. Sentryç›‘æ§é”™è¯¯ç‡
3. å¯¹æ¯”ä¸Šä¸€ç‰ˆæœ¬
4. å¦‚æœé”™è¯¯ç‡ä¸Šå‡>20%
5. è‡ªåŠ¨å›æ»šæˆ–å‘Šè­¦
"""
```

#### 21. Computer Use (ç³»ç»Ÿè‡ªåŠ¨åŒ–)

**èƒ½åŠ›**:
- å±å¹•æˆªå›¾
- é¼ æ ‡/é”®ç›˜æ§åˆ¶
- åº”ç”¨ç¨‹åºå¯åŠ¨
- æ–‡ä»¶ç®¡ç†

**ä½¿ç”¨åœºæ™¯**:
```python
# åœºæ™¯1: åº”ç”¨æµ‹è¯•è‡ªåŠ¨åŒ–
"""
Desktop App Testing:
1. å¯åŠ¨åº”ç”¨
2. æ¨¡æ‹Ÿç”¨æˆ·æ“ä½œ
3. éªŒè¯ç•Œé¢çŠ¶æ€
4. æˆªå›¾è®°å½•
5. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
"""

# åœºæ™¯2: å¤šåº”ç”¨åä½œ
"""
Cross-App Workflow:
1. ä»Excelè¯»å–æ•°æ®
2. æ‰“å¼€æµè§ˆå™¨
3. ç™»å½•ç³»ç»Ÿ
4. æ‰¹é‡æ“ä½œ
5. ç»“æœä¿å­˜
"""
```

---

### ğŸ“¦ å¯¹è±¡å­˜å‚¨

#### 22. MinIO (S3å…¼å®¹å­˜å‚¨)

**éƒ¨ç½²ä¿¡æ¯**:
- **ä½ç½®**: ~/minio-setup
- **ç«¯å£**: API: 9000, Console: 9001
- **å‡­è¯**: admin / SecretPass123456
- **å®¹é‡**: 524 GBå¯ç”¨
- **å®¢æˆ·ç«¯**: mc (MinIO Client)

**æ“ä½œæ–¹æ³•**:
```bash
# åŠ è½½ç¯å¢ƒå˜é‡
source ~/minio-setup/load-env.sh

# ä¸Šä¼ æ–‡ä»¶
mc cp local-file.pdf local/my-bucket/

# æ‰¹é‡ä¸Šä¼ 
mc mirror ./build-output/ local/builds/latest/

# ä¸‹è½½æ–‡ä»¶
mc cp local/my-bucket/file.pdf ./downloads/

# åˆ—å‡ºå¯¹è±¡
mc ls local/my-bucket/

# åˆ›å»ºbucket
mc mb local/new-project-assets

# è®¾ç½®å…¬å¼€è®¿é—®
mc anonymous set download local/my-bucket/public/

# ç”Ÿæˆåˆ†äº«é“¾æ¥
mc share download local/my-bucket/document.pdf --expire=7d
```

**Python SDKç¤ºä¾‹**:
```python
from minio import Minio

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = Minio(
    "localhost:9000",
    access_key="admin",
    secret_key="SecretPass123456",
    secure=False
)

# ä¸Šä¼ æ–‡ä»¶
client.fput_object(
    "my-bucket",
    "data/report.pdf",
    "/path/to/local/report.pdf"
)

# ä¸‹è½½æ–‡ä»¶
client.fget_object(
    "my-bucket",
    "data/report.pdf",
    "/path/to/save/report.pdf"
)

# åˆ—å‡ºå¯¹è±¡
objects = client.list_objects("my-bucket", prefix="data/")
for obj in objects:
    print(obj.object_name, obj.size)

# ç”Ÿæˆé¢„ç­¾åURL
url = client.presigned_get_object(
    "my-bucket",
    "data/report.pdf",
    expires=timedelta(days=7)
)
```

**è‡ªåŠ¨åŒ–åœºæ™¯**:
```python
# åœºæ™¯1: æ„å»ºäº§ç‰©å­˜å‚¨
"""
CI/CD Artifact Storage:
1. CIæ„å»ºå®Œæˆ
2. ä¸Šä¼ åˆ°MinIO/builds/{version}/
3. ç”Ÿæˆä¸‹è½½é“¾æ¥
4. Slacké€šçŸ¥å›¢é˜Ÿ
"""

# åœºæ™¯2: åª’ä½“æ–‡ä»¶ç®¡ç†
"""
Media Asset Pipeline:
1. ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡
2. å‹ç¼©å’Œä¼˜åŒ–
3. å­˜å‚¨åˆ°MinIO
4. ç”ŸæˆCDNé“¾æ¥
5. è¿”å›ç»™ç”¨æˆ·
"""

# åœºæ™¯3: å¤‡ä»½è‡ªåŠ¨åŒ–
"""
Automated Backup:
1. Celeryå®šæ—¶ä»»åŠ¡
2. å¯¼å‡ºæ•°æ®åº“
3. å‹ç¼©å¤‡ä»½æ–‡ä»¶
4. ä¸Šä¼ åˆ°MinIO/backups/
5. åˆ é™¤7å¤©å‰çš„å¤‡ä»½
"""

# åœºæ™¯4: æ—¥å¿—å½’æ¡£
"""
Log Archival:
1. æ”¶é›†åº”ç”¨æ—¥å¿—
2. æŒ‰æ—¥æœŸå‹ç¼©
3. ä¸Šä¼ åˆ°MinIO/logs/{date}/
4. æœ¬åœ°æ—¥å¿—æ¸…ç†
5. ä¿ç•™æœ€è¿‘30å¤©
"""

# åœºæ™¯5: AIç”Ÿæˆå†…å®¹å­˜å‚¨
"""
Generated Content Storage:
1. LLMç”Ÿæˆå†…å®¹
2. è½¬æ¢ä¸ºPDF/HTML
3. å­˜å‚¨åˆ°MinIO
4. è®°å½•åˆ°æ•°æ®åº“
5. ç”Ÿæˆåˆ†äº«é“¾æ¥
"""
```

---

## è‡ªåŠ¨åŒ–å¼€å‘åœºæ™¯

### ğŸ¯ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

#### åœºæ™¯1: ç«¯åˆ°ç«¯å†…å®¹ç”Ÿæˆè‡ªåŠ¨åŒ–

```python
"""
å®Œæ•´çš„å†…å®¹ç”Ÿæˆæµæ°´çº¿
ä»æ•°æ®é‡‡é›†åˆ°å†…å®¹å‘å¸ƒçš„å…¨è‡ªåŠ¨åŒ–æµç¨‹
"""

# ========================================
# é˜¶æ®µ1: æ•°æ®é‡‡é›† (æ¯å¤©å‡Œæ™¨2ç‚¹)
# ========================================

# 1.1 ä½¿ç”¨FirecrawlæŠ“å–ç«å“ç½‘ç«™
firecrawl_search({
  query: "best memory foam mattress 2025",
  limit: 20,
  sources: ["web"]
})

firecrawl_batch_scrape({
  urls: [ä»æœç´¢ç»“æœè·å–],
  formats: ["markdown", "html"]
})

# 1.2 ä¿å­˜åˆ°MongoDB
mongodb.insert_many({
  database: "geo_platform",
  collection: "scraped_content",
  documents: [æŠ“å–çš„å†…å®¹]
})

# 1.3 è°ƒç”¨InfraNodus APIåˆ†æ
# (é€šè¿‡è‡ªå®šä¹‰Pythonè„šæœ¬)
infranodus_client.create_graph(text_content)
network_data = infranodus_client.get_graph_data(graph_id)

# 1.4 å¯¼å…¥Neo4j
neo4j.batch_import({
  nodes: [Keyword, TopicCluster],
  relationships: [CO_OCCURS_WITH, BELONGS_TO]
})

# ========================================
# é˜¶æ®µ2: ç»“æ„æ´åˆ†æ (å‡Œæ™¨3ç‚¹)
# ========================================

# 2.1 æ‰§è¡Œç»“æ„æ´æ£€æµ‹
gaps = neo4j.execute_query(`
  MATCH (c1:TopicCluster), (c2:TopicCluster)
  WHERE id(c1) < id(c2)
  // è®¡ç®—æœºä¼šåˆ†æ•°
  RETURN c1, c2, opportunity_score
  ORDER BY opportunity_score DESC
  LIMIT 10
`)

# 2.2 ä¿å­˜Gapåˆ°Neo4j
for gap in gaps:
  neo4j.create_node({
    label: "Gap",
    properties: gap
  })

# 2.3 Slacké€šçŸ¥
slack.send_message({
  channel: "#content-team",
  text: f"å‘ç° {len(gaps)} ä¸ªæ–°å†…å®¹æœºä¼šï¼",
  attachments: [gapæ‘˜è¦]
})

# ========================================
# é˜¶æ®µ3: å†…å®¹ç”Ÿæˆ (æ‰‹åŠ¨è§¦å‘æˆ–å®šæ—¶)
# ========================================

# 3.1 ä»Gapç”ŸæˆPrompt
prompt = generate_prompt_from_gap(gap)

# 3.2 ä¿å­˜Promptåˆ°PostgreSQL
postgres.insert({
  table: "prompts",
  data: prompt
})

# 3.3 åˆ›å»ºBrief
context = neo4j.retrieve_context(prompt)
brief = llm.generate_brief(prompt, context)

# 3.4 ä¿å­˜Briefåˆ°PostgreSQL
postgres.insert({
  table: "briefs",
  data: brief
})

# 3.5 å‘é€åˆ°Feishuå®¡æ ¸
feishu.create_document({
  title: brief.title,
  content: [æ ¼å¼åŒ–çš„å†…å®¹]
})

# 3.6 ç­‰å¾…å®¡æ ¸ï¼ˆn8n webhookï¼‰
# å®¡æ ¸é€šè¿‡å...

# 3.7 ç”Ÿæˆæœ€ç»ˆAsset
asset = llm.generate_asset(brief, asset_type="BLOG_POST")

# 3.8 è®¡ç®—Citation Score
score = calculate_citation_score(asset)

# 3.9 å¦‚æœåˆ†æ•°>0.7ï¼Œè‡ªåŠ¨å‘å¸ƒ
if score > 0.7:
  # å‘å¸ƒåˆ°WordPress
  wordpress.create_post({
    title: asset.title,
    content: asset.content,
    status: "publish"
  })

  # ä¸Šä¼ åˆ°MinIOå¤‡ä»½
  minio.upload({
    bucket: "published-content",
    object: f"{asset.id}.html",
    content: asset.content
  })

  # æ›´æ–°PostgreSQL
  postgres.update({
    table: "assets",
    id: asset.id,
    data: {
      status: "PUBLISHED",
      published_at: now()
    }
  })

  # Slacké€šçŸ¥
  slack.send_message({
    channel: "#content-team",
    text: f"âœ… å†…å®¹å·²å‘å¸ƒ: {asset.title}",
    blocks: [è¯¦ç»†ä¿¡æ¯]
  })

# ========================================
# é˜¶æ®µ4: ç›‘æ§å’ŒæŠ¥å‘Š (æ¯å°æ—¶/æ¯å¤©)
# ========================================

# 4.1 ç³»ç»Ÿå¥åº·æ£€æŸ¥
health = check_system_health()

if health.score < 70:
  slack.send_alert({
    channel: "#ops-team",
    text: f"âš ï¸ ç³»ç»Ÿå¥åº·åˆ†æ•°: {health.score}%"
  })

# 4.2 æ”¶é›†æŒ‡æ ‡
metrics = {
  "neo4j_nodes": neo4j.count_nodes(),
  "gaps_identified": postgres.count("gaps", today),
  "assets_published": postgres.count("assets", today, status="PUBLISHED")
}

# 4.3 è®°å½•åˆ°MongoDB
mongodb.insert({
  collection: "daily_metrics",
  document: metrics
})

# 4.4 æ¯å‘¨ç”ŸæˆæŠ¥å‘Šï¼ˆå‘¨ä¸€æ—©ä¸Šï¼‰
if is_monday():
  report = generate_weekly_report()

  # ä¿å­˜åˆ°MinIO
  minio.upload({
    bucket: "reports",
    object: f"weekly-{date}.pdf",
    content: report.pdf
  })

  # å‘é€åˆ°Notion
  notion.create_page({
    parent: "Reports Database",
    properties: { title: report.title },
    children: [æŠ¥å‘Šå†…å®¹]
  })

  # é‚®ä»¶å‘é€
  email.send({
    to: ["team@company.com"],
    subject: "GEO Weekly Report",
    body: report.html,
    attachments: [report.pdf]
  })
```

#### åœºæ™¯2: AIè¾…åŠ©å¼€å‘è‡ªåŠ¨åŒ–

```python
"""
ä½¿ç”¨AIèƒ½åŠ›åŠ é€Ÿå¼€å‘æµç¨‹
"""

# ========================================
# 2.1 éœ€æ±‚åˆ†æ (Sequential Thinking)
# ========================================

user_request = "æ·»åŠ å¤šç§Ÿæˆ·æ”¯æŒ"

# Sequential Thinkingè‡ªåŠ¨åˆ†è§£é—®é¢˜
analysis = sequential_thinking.analyze({
  problem: user_request,
  context: [é¡¹ç›®ä»£ç åº“ä¿¡æ¯],
  steps: [
    "ç†è§£å¤šç§Ÿæˆ·éœ€æ±‚",
    "è¯„ä¼°ç°æœ‰æ¶æ„",
    "è®¾è®¡éš”ç¦»æ–¹æ¡ˆ",
    "è¯„ä¼°æ•°æ®åº“å½±å“",
    "è€ƒè™‘æ€§èƒ½å½±å“",
    "åˆ¶å®šè¿ç§»è®¡åˆ’"
  ]
})

# ä¿å­˜åˆ°Memory
memory.create_entities([
  {
    name: "Multi-tenancy Feature",
    entityType: "Feature",
    observations: [analysis.insights]
  }
])

# ========================================
# 2.2 æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡
# ========================================

# ä½¿ç”¨Memoryæ£€ç´¢ç›¸å…³æŠ€æœ¯å†³ç­–
related_decisions = memory.search_nodes("tenant isolation")

# ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ
tech_spec = llm.generate({
  prompt: f"""
  åŸºäºä»¥ä¸‹èƒŒæ™¯è®¾è®¡å¤šç§Ÿæˆ·æ–¹æ¡ˆ:
  - ç°æœ‰æ¶æ„: {analysis.current_architecture}
  - ç›¸å…³å†³ç­–: {related_decisions}
  - çº¦æŸæ¡ä»¶: {constraints}

  ç”Ÿæˆ:
  1. æ•°æ®éš”ç¦»ç­–ç•¥
  2. APIå˜æ›´
  3. æ•°æ®åº“Schemaå˜æ›´
  4. è¿ç§»æ­¥éª¤
  """
})

# ä¿å­˜åˆ°Feishu
feishu.create_document({
  title: "å¤šç§Ÿæˆ·æŠ€æœ¯æ–¹æ¡ˆ",
  content: [æ ¼å¼åŒ–çš„tech_spec]
})

# ========================================
# 2.3 è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆ
# ========================================

# è¯»å–ç°æœ‰ä»£ç 
models_code = filesystem.read_file("app/models.py")
api_code = filesystem.read_file("app/api/deps.py")

# ç”Ÿæˆæ–°ä»£ç 
new_models = llm.generate({
  prompt: f"""
  åŸºäºç°æœ‰ä»£ç :
  {models_code}

  æ·»åŠ å¤šç§Ÿæˆ·æ”¯æŒ:
  1. Tenantæ¨¡å‹
  2. TenantContext
  3. ç§Ÿæˆ·è¿‡æ»¤å™¨
  """
})

# å†™å…¥æ–‡ä»¶
filesystem.write_file({
  path: "app/models/tenant.py",
  content: new_models
})

# Gitæäº¤
github.create_branch({
  repo: "geo-platform",
  branch: "feature/multi-tenancy"
})

github.push_files({
  branch: "feature/multi-tenancy",
  files: [
    { path: "app/models/tenant.py", content: new_models }
  ],
  message: "Add multi-tenancy models"
})

# ========================================
# 2.4 è‡ªåŠ¨åŒ–æµ‹è¯•ç”Ÿæˆ
# ========================================

# ç”Ÿæˆæµ‹è¯•ä»£ç 
test_code = llm.generate({
  prompt: f"""
  ä¸ºä»¥ä¸‹ä»£ç ç”Ÿæˆpytestæµ‹è¯•:
  {new_models}

  åŒ…æ‹¬:
  1. æ¨¡å‹åˆ›å»ºæµ‹è¯•
  2. ç§Ÿæˆ·éš”ç¦»æµ‹è¯•
  3. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
  """
})

filesystem.write_file({
  path: "tests/test_tenant.py",
  content: test_code
})

# è¿è¡Œæµ‹è¯•
bash.run("pytest tests/test_tenant.py")

# ========================================
# 2.5 æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
# ========================================

# ç”ŸæˆAPIæ–‡æ¡£
api_docs = llm.generate({
  prompt: f"""
  åŸºäºä»£ç ç”ŸæˆAPIæ–‡æ¡£:
  {new_models}

  Markdownæ ¼å¼ï¼ŒåŒ…æ‹¬:
  1. ç«¯ç‚¹è¯´æ˜
  2. è¯·æ±‚ç¤ºä¾‹
  3. å“åº”ç¤ºä¾‹
  """
})

# æ›´æ–°æ–‡æ¡£
github.create_or_update_file({
  path: "docs/multi-tenancy.md",
  content: api_docs
})

# åŒæ­¥åˆ°Notion
notion.create_page({
  parent: "API Docs",
  title: "Multi-tenancy API",
  children: [api_docsè½¬ä¸ºNotion blocks]
})

# ========================================
# 2.6 åˆ›å»ºPR
# ========================================

github.create_pull_request({
  title: "Feature: Multi-tenancy support",
  head: "feature/multi-tenancy",
  base: "develop",
  body: f"""
  ## å˜æ›´æ‘˜è¦
  {tech_spec.summary}

  ## æŠ€æœ¯å®ç°
  {tech_spec.implementation}

  ## æµ‹è¯•
  - [x] å•å…ƒæµ‹è¯•é€šè¿‡
  - [ ] é›†æˆæµ‹è¯•
  - [ ] æ€§èƒ½æµ‹è¯•

  ## æ–‡æ¡£
  - [x] APIæ–‡æ¡£å·²æ›´æ–°
  - [x] NotionæŠ€æœ¯æ–¹æ¡ˆå·²åˆ›å»º
  """
})

# Slacké€šçŸ¥
slack.send_message({
  channel: "#dev-team",
  text: "ğŸš€ å¤šç§Ÿæˆ·åŠŸèƒ½PRå·²åˆ›å»ºï¼Œè¯·Review"
})
```

#### åœºæ™¯3: æ™ºèƒ½è¿ç»´è‡ªåŠ¨åŒ–

```python
"""
AIé©±åŠ¨çš„è¿ç»´è‡ªåŠ¨åŒ–
"""

# ========================================
# 3.1 å¼‚å¸¸æ£€æµ‹å’Œè¯Šæ–­
# ========================================

# ç›‘æ§ç³»ç»ŸæŒ‡æ ‡ (æ¯5åˆ†é’Ÿ)
metrics = prometheus.query({
  query: "http_request_duration_seconds_p95"
})

if metrics.value > 2.0:  # P95å»¶è¿Ÿ>2ç§’

  # ä½¿ç”¨Sequential Thinkingåˆ†æ
  diagnosis = sequential_thinking.analyze({
    problem: "APIå“åº”æ—¶é—´å¼‚å¸¸",
    symptoms: {
      "p95_latency": metrics.value,
      "timestamp": now(),
      "affected_endpoints": [...]
    },
    steps: [
      "æ”¶é›†ç›¸å…³æ—¥å¿—",
      "æ£€æŸ¥æ•°æ®åº“æ€§èƒ½",
      "åˆ†ææ…¢æŸ¥è¯¢",
      "æ£€æŸ¥å¤–éƒ¨ä¾èµ–",
      "è¯„ä¼°ç½‘ç»œçŠ¶å†µ",
      "å®šä½æ ¹æœ¬åŸå› "
    ]
  })

  # æ”¶é›†è¯¦ç»†æ—¥å¿—
  logs = mongodb.find({
    collection: "application_logs",
    filter: {
      timestamp: { $gte: now() - 5min },
      level: "ERROR"
    }
  })

  # æ£€æŸ¥Neo4jæ…¢æŸ¥è¯¢
  slow_queries = neo4j.execute_query(`
    CALL dbms.listQueries()
    YIELD query, elapsedTimeMillis
    WHERE elapsedTimeMillis > 1000
    RETURN query, elapsedTimeMillis
  `)

  # Sentryé”™è¯¯åˆ†æ
  recent_errors = sentry.search_events({
    query: "error.unhandled:true AND timestamp:>-5m"
  })

  # ä½¿ç”¨LLMç»¼åˆåˆ†æ
  root_cause = llm.analyze({
    prompt: f"""
    åˆ†æä»¥ä¸‹ç³»ç»Ÿå¼‚å¸¸ï¼š

    ç—‡çŠ¶: {diagnosis.symptoms}
    æ—¥å¿—: {logs}
    æ…¢æŸ¥è¯¢: {slow_queries}
    é”™è¯¯: {recent_errors}

    è¯·:
    1. è¯†åˆ«æ ¹æœ¬åŸå› 
    2. è¯„ä¼°å½±å“èŒƒå›´
    3. æä¾›ä¿®å¤å»ºè®®
    4. ç»™å‡ºç´§æ€¥ç¨‹åº¦ï¼ˆP0/P1/P2ï¼‰
    """
  })

  # åˆ›å»ºIssue
  issue_id = github.create_issue({
    title: f"[P{root_cause.priority}] {root_cause.title}",
    body: root_cause.details,
    labels: ["bug", "production", f"p{root_cause.priority}"]
  })

  # åˆ›å»ºSentry Issueå…³è”
  sentry.add_issue_comment({
    issue_id: recent_errors[0].id,
    comment: f"GitHub Issue: {issue_id}"
  })

  # å‘Šè­¦é€šçŸ¥
  slack.send_alert({
    channel: "#ops-team",
    priority: root_cause.priority,
    text: f"""
    ğŸš¨ {root_cause.title}

    æ ¹æœ¬åŸå› : {root_cause.root_cause}
    å½±å“èŒƒå›´: {root_cause.impact}
    å»ºè®®æ“ä½œ: {root_cause.recommendations}

    GitHub Issue: {issue_id}
    """
  })

  # å¦‚æœæ˜¯P0ï¼Œè‡ªåŠ¨æ‰§è¡Œä¿®å¤
  if root_cause.priority == 0:
    if root_cause.auto_fixable:
      # æ‰§è¡Œè‡ªåŠ¨ä¿®å¤è„šæœ¬
      bash.run(root_cause.fix_script)

      # éªŒè¯ä¿®å¤
      time.sleep(60)
      new_metrics = prometheus.query(...)

      if new_metrics.value < 1.0:
        slack.send_message({
          text: "âœ… è‡ªåŠ¨ä¿®å¤æˆåŠŸ"
        })
      else:
        slack.send_message({
          text: "âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥"
        })

# ========================================
# 3.2 æ™ºèƒ½æ‰©å®¹å†³ç­–
# ========================================

# åˆ†æè´Ÿè½½è¶‹åŠ¿
load_forecast = sequential_thinking.analyze({
  problem: "é¢„æµ‹æœªæ¥24å°æ—¶è´Ÿè½½",
  data: [å†å²è´Ÿè½½æ•°æ®],
  steps: [
    "åˆ†æå†å²æ¨¡å¼",
    "è¯†åˆ«å‘¨æœŸæ€§",
    "è€ƒè™‘ç‰¹æ®Šäº‹ä»¶",
    "é¢„æµ‹è´Ÿè½½è¶‹åŠ¿",
    "è®¡ç®—æ‰€éœ€èµ„æº"
  ]
})

if load_forecast.requires_scaling:
  # ç”Ÿæˆæ‰©å®¹æ–¹æ¡ˆ
  scaling_plan = llm.generate({
    prompt: f"""
    åŸºäºè´Ÿè½½é¢„æµ‹åˆ¶å®šæ‰©å®¹æ–¹æ¡ˆ:

    å½“å‰: {current_resources}
    é¢„æµ‹: {load_forecast}

    ç”Ÿæˆ:
    1. æ‰©å®¹æ—¶é—´ç‚¹
    2. èµ„æºæ•°é‡
    3. æˆæœ¬ä¼°ç®—
    4. å›æ»šè®¡åˆ’
    """
  })

  # åˆ›å»ºNotioné¡µé¢è®°å½•
  notion.create_page({
    title: f"æ‰©å®¹è®¡åˆ’ - {date}",
    properties: { "Status": "å¾…å®¡æ‰¹" },
    children: [scaling_plan]
  })

  # è¯·æ±‚å®¡æ‰¹
  slack.send_message({
    channel: "#ops-team",
    text: "éœ€è¦å®¡æ‰¹æ‰©å®¹è®¡åˆ’",
    blocks: [
      {
        type: "section",
        text: scaling_plan.summary
      },
      {
        type: "actions",
        elements: [
          { text: "æ‰¹å‡†", value: "approve" },
          { text: "æ‹’ç»", value: "reject" }
        ]
      }
    ]
  })

# ========================================
# 3.3 è‡ªåŠ¨åŒ–å¤‡ä»½å’Œæ¢å¤
# ========================================

# æ¯æ—¥å¤‡ä»½ä»»åŠ¡
def daily_backup():
  timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

  # 1. å¤‡ä»½Neo4j
  bash.run("docker exec neo4j neo4j-admin database dump neo4j")
  neo4j_backup = f"neo4j-{timestamp}.dump"

  # 2. å¤‡ä»½PostgreSQL
  bash.run(f"pg_dump -U claude > postgres-{timestamp}.sql")

  # 3. å¤‡ä»½MongoDB
  bash.run(f"mongodump --archive=mongodb-{timestamp}.archive")

  # 4. å‹ç¼©æ‰€æœ‰å¤‡ä»½
  bash.run(f"tar -czf backup-{timestamp}.tar.gz *.dump *.sql *.archive")

  # 5. ä¸Šä¼ åˆ°MinIO
  minio.upload({
    bucket: "backups",
    object: f"daily/{timestamp}/backup.tar.gz",
    file: f"backup-{timestamp}.tar.gz"
  })

  # 6. éªŒè¯å¤‡ä»½å®Œæ•´æ€§
  backup_size = minio.stat({
    bucket: "backups",
    object: f"daily/{timestamp}/backup.tar.gz"
  }).size

  # 7. è®°å½•åˆ°æ•°æ®åº“
  postgres.insert({
    table: "backup_history",
    data: {
      "timestamp": timestamp,
      "size_bytes": backup_size,
      "status": "completed"
    }
  })

  # 8. æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7å¤©ï¼‰
  old_backups = minio.list({
    bucket: "backups",
    prefix: "daily/",
    older_than: 7 * 24 * 3600
  })

  for backup in old_backups:
    minio.remove(backup)

  # 9. Slacké€šçŸ¥
  slack.send_message({
    channel: "#ops-team",
    text: f"âœ… æ¯æ—¥å¤‡ä»½å®Œæˆ\nå¤§å°: {backup_size / 1024 / 1024:.2f} MB"
  })

# ç¾éš¾æ¢å¤
def disaster_recovery(backup_timestamp):
  # 1. åœæ­¢æœåŠ¡
  bash.run("docker-compose down")

  # 2. ä»MinIOä¸‹è½½å¤‡ä»½
  minio.download({
    bucket: "backups",
    object: f"daily/{backup_timestamp}/backup.tar.gz",
    file: "restore.tar.gz"
  })

  # 3. è§£å‹
  bash.run("tar -xzf restore.tar.gz")

  # 4. æ¢å¤æ•°æ®åº“
  bash.run("neo4j-admin database load neo4j --from=neo4j.dump")
  bash.run("psql -U claude < postgres.sql")
  bash.run("mongorestore --archive=mongodb.archive")

  # 5. å¯åŠ¨æœåŠ¡
  bash.run("docker-compose up -d")

  # 6. éªŒè¯æ¢å¤
  health = check_system_health()

  if health.score > 90:
    slack.send_message({
      text: "âœ… ç³»ç»Ÿæ¢å¤æˆåŠŸ"
    })
  else:
    slack.send_alert({
      text: "âŒ ç³»ç»Ÿæ¢å¤å¼‚å¸¸ï¼Œéœ€è¦äººå·¥æ£€æŸ¥"
    })
```

---

## å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹1: ä¸€é”®éƒ¨ç½²å®Œæ•´å¼€å‘ç¯å¢ƒ

```bash
#!/bin/bash
# ä½¿ç”¨Claude Codeè‡ªåŠ¨åŒ–éƒ¨ç½²å¼€å‘ç¯å¢ƒ

echo "ğŸš€ å¼€å§‹éƒ¨ç½²GEO Platformå¼€å‘ç¯å¢ƒ..."

# 1. å…‹éš†ä»“åº“
git clone https://github.com/your-org/geo-platform.git
cd geo-platform

# 2. åˆ›å»ºç¯å¢ƒé…ç½®
cat > .env << EOF
NEO4J_URI=neo4j://localhost:7688
NEO4J_PASSWORD=development_password
POSTGRES_URL=postgresql://geo:geo@localhost:5437/geo_dev
REDIS_URL=redis://localhost:6382
OPENAI_API_KEY=${OPENAI_API_KEY}
EOF

# 3. å¯åŠ¨DockeræœåŠ¡
docker-compose up -d

# 4. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# 5. åˆå§‹åŒ–Neo4j Schema
python scripts/init_neo4j.py

# 6. è¿è¡Œæ•°æ®åº“è¿ç§»
alembic upgrade head

# 7. å¯¼å…¥ç¤ºä¾‹æ•°æ®
python scripts/seed_data.py

# 8. å¯åŠ¨åç«¯æœåŠ¡
uvicorn app.main:app --reload &

# 9. å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
cd frontend
npm install
npm run dev &

# 10. æ‰“å¼€æµè§ˆå™¨
sleep 5
open http://localhost:3000

echo "âœ… å¼€å‘ç¯å¢ƒéƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“ å‰ç«¯: http://localhost:3000"
echo "ğŸ“ åç«¯API: http://localhost:8000"
echo "ğŸ“ APIæ–‡æ¡£: http://localhost:8000/docs"
echo "ğŸ“ Neo4j Browser: http://localhost:7475"
```

### ç¤ºä¾‹2: AIè¾…åŠ©Code Review

```python
"""
ä½¿ç”¨Claude Codeè‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥
"""

async def ai_code_review(pr_number: int):
    # 1. è·å–PRä¿¡æ¯
    pr = await github.get_pull_request({
        "owner": "my-org",
        "repo": "geo-platform",
        "pull_number": pr_number
    })

    # 2. è·å–æ”¹åŠ¨æ–‡ä»¶
    files = await github.get_pull_request_files({
        "pull_number": pr_number
    })

    # 3. ä½¿ç”¨Sequential Thinkingåˆ†ææ¯ä¸ªæ–‡ä»¶
    reviews = []
    for file in files:
        if file.filename.endswith(('.py', '.ts', '.tsx')):
            content = await github.get_file_contents({
                "path": file.filename,
                "ref": pr.head.ref
            })

            # AIåˆ†æä»£ç 
            review = await llm.analyze({
                "prompt": f"""
                å®¡æŸ¥ä»¥ä¸‹ä»£ç å˜æ›´:

                æ–‡ä»¶: {file.filename}
                å˜æ›´ç±»å‹: {file.status}

                ```{file.language}
                {file.patch}
                ```

                è¯·æ£€æŸ¥:
                1. ä»£ç è´¨é‡å’Œå¯è¯»æ€§
                2. æ½œåœ¨çš„bug
                3. æ€§èƒ½é—®é¢˜
                4. å®‰å…¨éšæ‚£
                5. æµ‹è¯•è¦†ç›–
                6. æ–‡æ¡£å®Œæ•´æ€§

                ä¸ºæ¯ä¸ªé—®é¢˜æä¾›:
                - ä¸¥é‡ç¨‹åº¦ (HIGH/MEDIUM/LOW)
                - å…·ä½“ä½ç½®
                - é—®é¢˜æè¿°
                - æ”¹è¿›å»ºè®®
                """
            })

            reviews.append({
                "file": file.filename,
                "review": review
            })

    # 4. ç”Ÿæˆæ€»ç»“
    summary = await llm.generate({
        "prompt": f"""
        æ€»ç»“ä»£ç å®¡æŸ¥ç»“æœ:

        {reviews}

        ç”Ÿæˆ:
        1. æ€»ä½“è¯„ä»·
        2. ä¸»è¦é—®é¢˜åˆ—è¡¨
        3. æ”¹è¿›å»ºè®®
        4. æ˜¯å¦å»ºè®®åˆå¹¶
        """
    })

    # 5. åˆ›å»ºPRè¯„è®º
    comment_body = f"""
    ## ğŸ¤– AI Code Review

    {summary.overall}

    ### ä¸»è¦å‘ç°

    {summary.findings}

    ### è¯¦ç»†å®¡æŸ¥

    """

    for review in reviews:
        comment_body += f"""
        #### {review.file}

        {review.review}

        ---
        """

    comment_body += f"""

    ### å»ºè®®

    {summary.recommendations}

    **åˆå¹¶å»ºè®®**: {summary.merge_recommendation}
    """

    await github.create_pull_request_review({
        "pull_number": pr_number,
        "body": comment_body,
        "event": "COMMENT"
    })

    # 6. Slacké€šçŸ¥
    await slack.send_message({
        "channel": "#code-review",
        "text": f"AI Code Reviewå®Œæˆ: PR #{pr_number}",
        "blocks": [
            {
                "type": "section",
                "text": f"*{pr.title}*\n{summary.overall}"
            },
            {
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": "æŸ¥çœ‹PR",
                        "url": pr.html_url
                    }
                ]
            }
        ]
    })
```

### ç¤ºä¾‹3: æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆ

```python
"""
è‡ªåŠ¨ç”Ÿæˆé¡¹ç›®æ–‡æ¡£
"""

async def generate_project_documentation():
    # 1. æ‰«æé¡¹ç›®ç»“æ„
    project_structure = await filesystem.directory_tree({
        "path": "/project"
    })

    # 2. åˆ†æä¸»è¦æ–‡ä»¶
    key_files = [
        "README.md",
        "app/main.py",
        "app/api/v1/api.py",
        "app/models/*.py",
        "app/services/*.py"
    ]

    file_contents = {}
    for pattern in key_files:
        files = await filesystem.search_files({
            "pattern": pattern
        })

        for file in files:
            content = await filesystem.read_file({
                "path": file.path
            })
            file_contents[file.path] = content

    # 3. ä½¿ç”¨Sequential Thinkingåˆ†æé¡¹ç›®
    analysis = await sequential_thinking.analyze({
        "problem": "ç†è§£é¡¹ç›®æ¶æ„å’Œç”Ÿæˆæ–‡æ¡£",
        "context": {
            "structure": project_structure,
            "files": file_contents
        },
        "steps": [
            "åˆ†æé¡¹ç›®ç»“æ„",
            "è¯†åˆ«æ ¸å¿ƒæ¨¡å—",
            "ç†è§£æ•°æ®æµ",
            "æå–APIç«¯ç‚¹",
            "è¯†åˆ«ä¾èµ–å…³ç³»",
            "ç”Ÿæˆæ–‡æ¡£å¤§çº²"
        ]
    })

    # 4. ç”Ÿæˆå„éƒ¨åˆ†æ–‡æ¡£
    docs = {}

    # 4.1 Architecture Overview
    docs["architecture"] = await llm.generate({
        "prompt": f"""
        åŸºäºåˆ†æç”Ÿæˆæ¶æ„æ–‡æ¡£:

        {analysis.architecture}

        åŒ…æ‹¬:
        1. ç³»ç»Ÿæ¶æ„å›¾ (Mermaid)
        2. æŠ€æœ¯æ ˆ
        3. ç›®å½•ç»“æ„è¯´æ˜
        4. æ•°æ®æµå›¾
        """
    })

    # 4.2 API Documentation
    docs["api"] = await llm.generate({
        "prompt": f"""
        ç”ŸæˆAPIæ–‡æ¡£:

        {analysis.api_endpoints}

        æ¯ä¸ªç«¯ç‚¹åŒ…æ‹¬:
        1. URLå’Œæ–¹æ³•
        2. å‚æ•°è¯´æ˜
        3. è¯·æ±‚ç¤ºä¾‹
        4. å“åº”ç¤ºä¾‹
        5. é”™è¯¯ä»£ç 
        """
    })

    # 4.3 Database Schema
    docs["database"] = await llm.generate({
        "prompt": f"""
        ç”Ÿæˆæ•°æ®åº“æ–‡æ¡£:

        {analysis.database_schema}

        åŒ…æ‹¬:
        1. ERå›¾ (Mermaid)
        2. è¡¨ç»“æ„è¯´æ˜
        3. å…³ç³»è¯´æ˜
        4. ç´¢å¼•ç­–ç•¥
        """
    })

    # 4.4 Deployment Guide
    docs["deployment"] = await llm.generate({
        "prompt": f"""
        ç”Ÿæˆéƒ¨ç½²æ–‡æ¡£:

        {analysis.deployment_info}

        åŒ…æ‹¬:
        1. ç¯å¢ƒè¦æ±‚
        2. éƒ¨ç½²æ­¥éª¤
        3. é…ç½®è¯´æ˜
        4. å¸¸è§é—®é¢˜
        """
    })

    # 5. ç”Ÿæˆä¸»README
    readme = await llm.generate({
        "prompt": f"""
        ç”Ÿæˆé¡¹ç›®README:

        é¡¹ç›®ä¿¡æ¯: {analysis.project_info}

        ç»“æ„:
        1. é¡¹ç›®ç®€ä»‹
        2. å¿«é€Ÿå¼€å§‹
        3. åŠŸèƒ½ç‰¹æ€§
        4. æŠ€æœ¯æ¶æ„
        5. å¼€å‘æŒ‡å—
        6. APIæ–‡æ¡£é“¾æ¥
        7. è´¡çŒ®æŒ‡å—
        """
    })

    # 6. å†™å…¥æ–‡ä»¶
    await filesystem.write_file({
        "path": "/project/README.md",
        "content": readme
    })

    await filesystem.write_file({
        "path": "/project/docs/ARCHITECTURE.md",
        "content": docs["architecture"]
    })

    await filesystem.write_file({
        "path": "/project/docs/API.md",
        "content": docs["api"]
    })

    await filesystem.write_file({
        "path": "/project/docs/DATABASE.md",
        "content": docs["database"]
    })

    await filesystem.write_file({
        "path": "/project/docs/DEPLOYMENT.md",
        "content": docs["deployment"]
    })

    # 7. åŒæ­¥åˆ°Notion
    # åˆ›å»ºNotion Database
    db_id = await notion.create_database({
        "parent": {"page_id": "workspace-root"},
        "title": "GEO Platform Docs",
        "properties": {
            "Name": {"title": {}},
            "Category": {"select": {}},
            "Status": {"select": {}}
        }
    })

    # åˆ›å»ºæ–‡æ¡£é¡µé¢
    for doc_name, doc_content in docs.items():
        await notion.create_page({
            "parent": {"database_id": db_id},
            "properties": {
                "Name": {"title": [{"text": {"content": doc_name}}]},
                "Category": {"select": {"name": "Documentation"}},
                "Status": {"select": {"name": "Published"}}
            },
            "children": [
                # è½¬æ¢Markdownä¸ºNotion blocks
                convert_markdown_to_notion_blocks(doc_content)
            ]
        })

    # 8. Gitæäº¤
    await github.push_files({
        "branch": "docs/auto-generated",
        "files": [
            {"path": "README.md", "content": readme},
            {"path": "docs/ARCHITECTURE.md", "content": docs["architecture"]},
            {"path": "docs/API.md", "content": docs["api"]},
            {"path": "docs/DATABASE.md", "content": docs["database"]},
            {"path": "docs/DEPLOYMENT.md", "content": docs["deployment"]}
        ],
        "message": "docs: Auto-generate project documentation"
    })

    # 9. åˆ›å»ºPR
    pr = await github.create_pull_request({
        "title": "ğŸ“š Auto-generated documentation",
        "head": "docs/auto-generated",
        "base": "main",
        "body": """
        ## ğŸ“š Documentation Update

        This PR contains auto-generated documentation including:

        - âœ… README.md
        - âœ… Architecture documentation
        - âœ… API documentation
        - âœ… Database schema documentation
        - âœ… Deployment guide

        The documentation has been automatically generated based on code analysis
        and synchronized to Notion.

        Please review and merge if accurate.
        """
    })

    # 10. Slacké€šçŸ¥
    await slack.send_message({
        "channel": "#dev-team",
        "text": "ğŸ“š é¡¹ç›®æ–‡æ¡£å·²è‡ªåŠ¨ç”Ÿæˆå¹¶åŒæ­¥",
        "blocks": [
            {
                "type": "section",
                "text": f"æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œè¯·Review: {pr.html_url}"
            },
            {
                "type": "section",
                "text": f"Notionæ–‡æ¡£: [æŸ¥çœ‹]({notion_url})"
            }
        ]
    })
```

---

## æœ€ä½³å®è·µ

### 1. èµ„æºç»„åˆä½¿ç”¨

#### æ¨¡å¼1: Webæ•°æ®é‡‡é›† + å›¾è°±æ„å»º

```python
# æœ€ä½³ç»„åˆ:
Firecrawl â†’ InfraNodus â†’ Neo4j â†’ Graph-RAG

# ä¸ºä»€ä¹ˆ:
- Firecrawl: é«˜è´¨é‡å†…å®¹æå–
- InfraNodus: è¯­ä¹‰ç½‘ç»œåˆ†æ
- Neo4j: å›¾è°±å­˜å‚¨å’ŒæŸ¥è¯¢
- Graph-RAG: æ™ºèƒ½é—®ç­”
```

#### æ¨¡å¼2: ä»£ç å¼€å‘ + åä½œ

```python
# æœ€ä½³ç»„åˆ:
Sequential Thinking â†’ Memory â†’ GitHub â†’ Slack â†’ Notion

# ä¸ºä»€ä¹ˆ:
- Sequential Thinking: é—®é¢˜åˆ†è§£
- Memory: çŸ¥è¯†ç§¯ç´¯
- GitHub: ä»£ç ç®¡ç†
- Slack: å®æ—¶é€šçŸ¥
- Notion: æ–‡æ¡£æ²‰æ·€
```

#### æ¨¡å¼3: æ•°æ®åˆ†æ + å¯è§†åŒ–

```python
# æœ€ä½³ç»„åˆ:
MongoDB/PostgreSQL â†’ Pandas â†’ D3.js â†’ MinIO

# ä¸ºä»€ä¹ˆ:
- MongoDB/PostgreSQL: æ•°æ®å­˜å‚¨
- Pandas: æ•°æ®åˆ†æ
- D3.js: å¯è§†åŒ–
- MinIO: æŠ¥å‘Šå­˜å‚¨
```

### 2. è‡ªåŠ¨åŒ–åˆ†å±‚ç­–ç•¥

```
ç¬¬1å±‚: æ•°æ®é‡‡é›†è‡ªåŠ¨åŒ–
â”œâ”€ Firecrawlå®šæ—¶æŠ“å–
â”œâ”€ GitHub Webhookè§¦å‘
â””â”€ n8nè°ƒåº¦ä»»åŠ¡

ç¬¬2å±‚: æ•°æ®å¤„ç†è‡ªåŠ¨åŒ–
â”œâ”€ InfraNodusåˆ†æ
â”œâ”€ Neo4jå¯¼å…¥
â””â”€ Redisç¼“å­˜

ç¬¬3å±‚: ä¸šåŠ¡é€»è¾‘è‡ªåŠ¨åŒ–
â”œâ”€ Graph-RAGé—®ç­”
â”œâ”€ å†…å®¹ç”Ÿæˆ
â””â”€ è¯„åˆ†è®¡ç®—

ç¬¬4å±‚: é€šçŸ¥å’Œåä½œè‡ªåŠ¨åŒ–
â”œâ”€ Slacké€šçŸ¥
â”œâ”€ Notionæ–‡æ¡£
â””â”€ Emailå‘é€

ç¬¬5å±‚: ç›‘æ§å’Œè¿ç»´è‡ªåŠ¨åŒ–
â”œâ”€ Sentryé”™è¯¯è¿½è¸ª
â”œâ”€ Prometheusç›‘æ§
â””â”€ è‡ªåŠ¨å¤‡ä»½
```

### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
# æœ€ä½³å®è·µ: æŒ‡æ•°é€€é¿é‡è¯•

import tenacity

@tenacity.retry(
    stop=tenacity.stop_after_attempt(3),
    wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
    retry=tenacity.retry_if_exception_type(APIError)
)
async def call_external_api():
    # APIè°ƒç”¨
    pass

# è®°å½•å¤±è´¥åˆ°MongoDB
try:
    result = await call_external_api()
except Exception as e:
    await mongodb.insert({
        "collection": "failed_jobs",
        "document": {
            "job_type": "api_call",
            "error": str(e),
            "timestamp": now(),
            "retry_count": 3
        }
    })

    # Slackå‘Šè­¦
    await slack.send_alert({
        "text": f"APIè°ƒç”¨å¤±è´¥: {e}"
    })
```

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

```python
# 1. ä½¿ç”¨ç¼“å­˜
@cache(redis_client, expire=300)
async def get_expensive_data():
    # æ˜‚è´µçš„è®¡ç®—
    pass

# 2. æ‰¹é‡æ“ä½œ
# âŒ é”™è¯¯: å¾ªç¯æ’å…¥
for item in items:
    await neo4j.create_node(item)

# âœ… æ­£ç¡®: æ‰¹é‡æ’å…¥
await neo4j.batch_create_nodes(items)

# 3. å¼‚æ­¥å¹¶å‘
# âŒ é”™è¯¯: ä¸²è¡Œ
for url in urls:
    data = await firecrawl_scrape(url)

# âœ… æ­£ç¡®: å¹¶å‘
tasks = [firecrawl_scrape(url) for url in urls]
results = await asyncio.gather(*tasks)

# 4. æ•°æ®åº“ç´¢å¼•
# ç¡®ä¿é¢‘ç¹æŸ¥è¯¢çš„å­—æ®µæœ‰ç´¢å¼•
CREATE INDEX idx_keyword_name ON Keyword(name);
CREATE INDEX idx_product_rating ON Product(rating);
```

### 5. å®‰å…¨å»ºè®®

```python
# 1. æ•æ„Ÿä¿¡æ¯åŠ å¯†
from cryptography.fernet import Fernet

cipher = Fernet(key)
encrypted_api_key = cipher.encrypt(api_key.encode())

# å­˜å‚¨åˆ°ç¯å¢ƒå˜é‡ï¼Œä¸è¦ç¡¬ç¼–ç 
os.environ['ENCRYPTED_API_KEY'] = encrypted_api_key

# 2. å®¡è®¡æ—¥å¿—
@audit_log
async def sensitive_operation():
    # è‡ªåŠ¨è®°å½•æ“ä½œåˆ°MongoDB
    pass

# 3. é€Ÿç‡é™åˆ¶
@rate_limit(max_calls=100, period=60)
async def api_endpoint():
    pass

# 4. è¾“å…¥éªŒè¯
from pydantic import BaseModel, validator

class DataSourceInput(BaseModel):
    url: str

    @validator('url')
    def validate_url(cls, v):
        if not v.startswith(('http://', 'https://')):
            raise ValueError('Invalid URL')
        return v
```

---

## æ€»ç»“

### ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

1. **å®Œæ•´çš„æŠ€æœ¯æ ˆ** - ä»æ•°æ®åˆ°å‘å¸ƒçš„å…¨é“¾è·¯æ”¯æŒ
2. **AIå¢å¼º** - Sequential Thinking + Memoryæå‡å¼€å‘æ•ˆç‡
3. **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜** - å‡å°‘90%é‡å¤æ€§å·¥ä½œ
4. **å¯æ‰©å±•æ€§å¼º** - å¾®æœåŠ¡æ¶æ„ï¼Œæ˜“äºæ‰©å±•
5. **åä½œå‹å¥½** - GitHub/Slack/Notionæ— ç¼é›†æˆ

### ğŸ“Š æ•ˆç‡æå‡

- **å¼€å‘é€Ÿåº¦**: æå‡ 3-5å€
- **ä»£ç è´¨é‡**: AI Code Reviewé™ä½50%bug
- **æ–‡æ¡£å®Œæ•´æ€§**: è‡ªåŠ¨ç”Ÿæˆï¼Œå§‹ç»ˆåŒæ­¥
- **è¿ç»´æ•ˆç‡**: è‡ªåŠ¨åŒ–ç›‘æ§å’Œå‘Šè­¦
- **å›¢é˜Ÿåä½œ**: å®æ—¶é€šçŸ¥å’ŒçŸ¥è¯†æ²‰æ·€

### ğŸš€ ä¸‹ä¸€æ­¥

1. **é€‰æ‹©åœºæ™¯** - ä»æœ€ç—›çš„åœºæ™¯å¼€å§‹
2. **å°æ­¥å¿«è·‘** - å…ˆè‡ªåŠ¨åŒ–ä¸€ä¸ªæµç¨‹
3. **æŒç»­ä¼˜åŒ–** - æ”¶é›†åé¦ˆï¼Œè¿­ä»£æ”¹è¿›
4. **æ‰©å±•åº”ç”¨** - æ¨å¹¿åˆ°å…¶ä»–åœºæ™¯

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*
*æœ€åæ›´æ–°: 2025-10-16*
